//a side-by-side reference sheet//

**[[[computer-algebra|sheet one:]]]** [[[computer-algebra#grammar-invocation|grammar and invocation]]] | [[[computer-algebra#var-expr|variables and expressions]]] | [[[computer-algebra#arithmetic-logic|arithmetic and logic]]] | [[[computer-algebra#strings|strings]]] | [[[computer-algebra#arrays|arrays]]] | [[[computer-algebra#sets|sets]]] | [[[computer-algebra#arith-seq|arithmetic sequences]]] | [[[computer-algebra#dictionaries|dictionaries]]] | [[[computer-algebra#functions|functions]]] | [[[computer-algebra#execution-control|execution control]]] | [[[computer-algebra#exceptions|exceptions]]] | [[[computer-algebra#streams|streams]]] | [[[computer-algebra#files|files]]] | [[[computer-algebra#directories|directories]]] | [[[computer-algebra#libraries-namespaces|libraries and namespaces]]] |  [[[computer-algebra#reflection|reflection]]]
 
**sheet two:** [#symbolic-expr symbolic expressions] | [#calculus calculus] | [#equations-unknowns equations and unknowns] | [#optimization optimization] | [#vectors vectors] | [#matrices matrices] | [#combinatorics combinatorics] | [#number-theory number theory] |  [#polynomials polynomials] | [#trigonometry trigonometry] | [#special-functions special functions] | [#permutations permutations] |  [#descriptive-statistics descriptive statistics] | [#distributions distributions] | [#statistical-tests statistical tests]

[#bar-charts bar charts] | [#scatter-plots scatter plots] | [#line-charts line charts] | [#surface-charts surface charts] | [#chart-options chart options]

||~ ||~ [#mathematica mathematica]||~ [#sympy sympy]||~ [#sage sage]||~ [#maxima maxima]||
||||||||||~ [[# symbolic-expr]][#symbolic-expr-note symbolic expressions]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# symbolic-expr-literal]][#symbolic-expr-literal-note literal]||expr = 1 + x + x^2||x = symbols('x') _
 _
expr = 1 + x + x^2||expr = 1 + x + x^2||expr = 1 + x + x^2;||
||[[# prevent-simplification]][#prevent-simplification-note prevent simplification]||HoldForm[x + x] _
x + x @@//@@ HoldForm|| || || ||
||[[# symbolic-expr-var-update]][#symbolic-expr-var-update-note variable update]||expr = 1 + x _
x = 3 _
##gray|(* 4: *)## _
expr||x = symbols('x') _
expr = 1 + x _
x = 3 _
##gray|# 1 + x:## _
expr||expr = 1 + x _
x = 7 _
##gray|# 1 + x:## _
expr||expr: 1 + x; _
x: 3; _
##gray|/* 1 + x: */## _
expr;||
||[[# symbolic-expr-subst]][#symbolic-expr-subst-note substitute]||##gray|(* {3, 3}: *)## _
ReplaceAll[{x, x}, x -> 3] _
 _
##gray|(* {3, 3}: *)## _
{x, x} /. x -> 3 _
 _
##gray|(* {3, 4}: *)## _
{x, y} /. {x -> 3, y -> 4}||Matrix([x, x]).subs(x, 3)||vector([x, x]).subs({x: 3})||##gray|/* [3, 3]: */## _
subst(3, x, [x, x]);||
||[[# piecewise-symbolic-expr]][#piecewise-symbolic-expr-note piecewise-defined expression]||Piecewise[@@{{x, x >= 0}, {-x, x < 0}}@@] _
 _
##gray|(* otherwise case: *)## _
Piecewise[@@{{-x, x < 0}}@@, x]||Piecewise((-x, x < 0), (x, x >= 0)) _
 _
##gray|# otherwise case:## _
Piecewise((-x, x < 0), (x, True))||piecewise([ _
@<&nbsp;&nbsp;>@((-infinity,0), -x), _
@<&nbsp;&nbsp;>@((0,infinity), x)])||if x < 0 then -x else x; _
 _
##gray|/* integrating over piecewise-defined expression fails */##||
||[[# simplify]][#simplify-note simplify]||Simplify[Cos[x]^2 + Sin[x]^2] _
 _
##gray|(* perform more simplications: *)## _
FullSimplify[-(1/2) I E^(-I x) (-1 + E^(2 I x))]||simplify(cos(x)@@**@@2 + sin(x)@@**@@2)|| || ||
||[[# assumption]][#assumption-note assumption]||Simplify[Sqrt[x^2], Assumptions -> x >= 0] _
Simplify[(-1)^(n * (n + 1)), _
@<&nbsp;&nbsp;>@Assumptions -> Element[n, Integers]] _
 _
##gray|(* perform fewer simplications: *)## _
Refine[Sqrt[x^2], Assumptions -> x >= 0] _
Refine[(-1)^(n * (n + 1)), Element[n, Integers]]||x = symbols('x', positive=True) _
sqrt(x ** 2) _
 _
n = symbols('n', integer=True) _
(-1)@@**@@((n) * (n + 1))||assume(x > 0) _
sqrt(x^2)||assume(x > 0); _
sqrt(x^2); _
 _
##gray|/* There is no assumption predicate for _
@<&nbsp;&nbsp;&nbsp;>@integer variables. */##||
||[[# assumption-predicates]][#assumption-predicates-note assumption predicates]||Element[x, Complexes] _
Element[x, Reals] _
Element[x, Algebraics] _
Element[x, Rationals] _
Element[x, Integers] _
Element[x, Primes] _
Element[x, Integers] && Mod[x, 5] == 0 _
Element[x, Booleans] _
 _
##gray|(* assumptions can use inequalities and logical operators: *)## _
x > 0 @@||@@ x < 0||##gray|# a partial list:## _
complex _
real _
algebraic _
rational _
integer _
positive _
nonpositive _
negative _
nonnegative _
nonzero _
prime _
odd _
even||assume(x, 'complex') _
assume(x, 'real') _
assume(x, 'rational') _
assume(x, 'integer') _
assume(x, 'odd') _
assume(x, 'even')||##gray|//Assumptions can only be created using relational operators.//##||
||[[# list-assumptions]][#list-assumptions-note list assumptions]||##gray|//None.  Assumptions are always local.//##||x.assumptions0||assumptions()||facts(x); _
 _
##gray|# assumptions on all symbols:## _
facts();||
||[[# rm-assumption]][#rm-assumption-note remove assumption]||##gray|//None.  Assumptions are always local.//##||##gray|# removes all assumptions about x:## _
x = symbols('x')||forget(x > 0) _
 _
##gray|# rm all assumptions:## _
forget()||forget(x > 0);||
||||||||||~ [[# calculus]][#calculus-note calculus]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# limit]][#limit-note limit] _
@<&nbsp;>@||Limit[Sin[x]/x, x -> 0]||limit(sin(x)/x, x, 0)||limit(sin(x)/x, x=0)||limit(sin(x)/x, x, 0);||
||[[# limit-at-infinity]][#limit-at-infinity-note limit at infinity] _
@<&nbsp;>@||Limit[1/x, x -> Infinity]||limit(1/x, x, oo)||limit(1/x, x=infinity)||limit(1/x, x, inf);||
||[[# one-sided-limit]][#one-sided-limit-note one-sided limit] _
 _
##gray|//from left, from right//##||Limit[1/x, x -> 0, Direction -> 1] _
Limit[1/x, x -> 0, Direction -> -1]||limit(1/x, x, 0, '-') _
limit(1/x, x, 0, '+')||limit(1/x, x=0, dir='-') _
limit(1/x, x=0, dir='+')||limit(1/x, x, 0, minus); _
limit(1/x, x, 0, plus);||
||[[# derivative]][#derivative-note derivative]||D[x^3 + x + 3, x] _
 _
D[x^3 + x + 3, x] /. x -> 2||diff(x@@**@@3 + x + 3, x) _
 _
diff(x@@**@@3 + x + 3, x).subs(x, 2)||diff(x^3 + x + 3, x) _
 _
diff(x^3 + x + 3, x).subs({x: 2}) _
 _
##gray|# derivative is synonym of diff##||diff(x^3 + x + 3, x); _
 _
at(diff(x^3 + x + 3, x), [x=2]);||
||[[# derivative-func]][#derivative-func-note derivative of a function]||f[x_] = x^3 + x + 3 _
 _
##gray|(* returns expression: *)## _
D[f[x, x]] _
 _
##gray|(* return functions: *)## _
f' _
Derivative[1][f] _
 _
##gray|(* evaluating derivative at a point: *)## _
f'[2] _
Derivative[1][f][2]|| ||f(x) = x^3 + x + 3 _
 _
diff(f) _
 _
diff(f)(2)|| ||
||[[# derivative-const]][#derivative-const-note constants]||##gray|(* a depends on x; b does not: *)## _
D[a x + b, x,  NonConstants -> {a}] _
 _
Dt[a x + b, x, Constants -> {b}]|| || ||##gray|/* symbols constant unless declared with depends: */## _
depends(a, x); _
diff(a * x + b, x); _
 _
##gray|/* makes a constant again: */## _
remove(a, dependency);||
||[[# higher-order-derivative]][#higher-order-derivative-note higher order derivative]||D[Log[x], {x, 3}] _
Log'''[x] _
Derivative[3][Log][x]||diff(log(x), x, 3)||diff(log(x), x, 3)||diff(log(x), x, 3);||
||[[# mixed-partial-derivative]][#mixed-partial-derivative-note mixed partial derivative]||D[x^9 * y^8, x, y, y] _
D[x^9 * y^8, x, {y, 2}]||diff(x@@**@@9 * y@@**@@8, x, y, y)||diff(x^9 * y^8, x, 1).diff(y, 2)||diff(x^9 * y^8, x, 1, y, 2);||
||[[# div-grad-curl]][#div-grad-curl-note div, grad, and curl]||Div[{x^2, x * y, x * y * z}, {x, y, z}] _
 _
Grad[2 * x * y * z^2, {x, y, z}] _
 _
Curl[{x * y * z, y^2, 0}, {x, y, z}]|| || || ||
||[[# antiderivative]][#antiderivative-note antiderivative] _
@<&nbsp;>@||Integrate[x^3 + x + 3, x]||integrate(x@@**@@3 + x + 3, x)||integral(x^3 + x + 3, x)||integrate(x^3 + x + 3, x);||
||[[# definite-integral]][#definite-integral-note definite integral] _
@<&nbsp;>@||Integrate[x^3 + x + 3, {x, 0, 1}]||integrate(x@@**@@3 + x + 3, [x, 0, 1])||integral(x^3 + x + 3, x, 0, 1)||integrate(x^3 + x + 3, x, 0, 1);||
||[[# improper-integral]][#improper-integral-note improper integral] _
@<&nbsp;>@||Integrate[Exp[-x], {x, 0, Infinity}]||integrate(exp(-x), (x, 0, oo))||integral(exp(-x), x, 0, infinity)||integrate(exp(-x), x, 0, inf);||
||[[# double-integral]][#double-integral-note double integral]||##gray|(* integrates over y first: *)## _
Integrate[x^2 + y^2, {x, 0, 1}, {y, 0, x}]||f = integrate(@@x**2 + y**2@@, (y, 0, x)) _
integrate(f, (x, 0, 1))||integral(integral(x^2+y^2, y, 0, x), x, 0, 1)||integrate( _
@<&nbsp;&nbsp;>@integrate(x^2+y^2, y, 0, x), x, 0, 1);||
||[[# find-poles]][#find-poles-note find poles] _
@<&nbsp;>@|| || || || ||
||[[# residue]][#residue-note residue] _
@<&nbsp;>@||Residue[1/(z - I), {z, I}]||residue(1/(z-I), z, I)||f(z) = 1/(z - I) _
f.maxima_methods().residue(z, I)||residue(1 / (z - %i), z, %i);||
||[[# sum]][#sum-note sum] _
@<&nbsp;>@||Sum[2^i, {i, 1, 10}]||Sum(2@@**@@i, (i, 1, 10)).doit()||sum(2^i for i in (1..10))||sum(2^i, i, 1, 10);||
||[[# series-sum]][#series-sum-note series sum] _
@<&nbsp;>@||Sum[2^-n, {n, 1, Infinity}]||Sum(2@@**@@(-n), (n, 1, oo)).doit()||sum(2^-n, n, 1, infinity)||sum(2^-n, n, 1, inf), simpsum;||
||[[# series-expansion-func]][#series-expansion-func-note series expansion of function]||Series[Cos[x], {x, 0, 10}]||series(cos(x), x, n=11)||taylor(cos(x), x, 0, 10)||taylor(cos(x), [x, 0, 10]);||
||[[# omitted-order-term]][#omitted-order-term-note omitted order term]||expr = 1 + x + x/2 + x^2/6 + O[x]^3 _
 _
##gray|(* remove omitted order term: *)## _
Normal[expr]|| || || ||
||[[# product]][#product-note product] _
@<&nbsp;>@||Product[2*i + 1, {i, 0, 9}]||Product(2*i + 1, (i, 0, 9)).doit()||prod(2*i + 1 for i in (0..9))||product(2*i + 1, i, 0, 9);||
||||||||||~ [[# equations-unknowns]][#equations-unknowns-note equations and unknowns]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# solve-eqn]][#solve-eqn-note solve equation] _
@<&nbsp;>@||Solve[x^3 + x + 3 == 0, x]||solve(x@@**@@3 + x + 3, x)||solve(x^3 + x + 3 == 0, x)||solve(x^3 + x + 3 = 0, x);||
||[[# solve-eqns]][#solve-eqns-note solve equations]||Solve[x + y == 3 &&  x == 2 * y, _
@<&nbsp;&nbsp;>@{x, y}] _
 _
##gray|(* or: *)## _
Solve[{x + y == 3, x == 2 * y}, {x, y}]||solve([x + y - 3, 3*x - 2*y], [x, y])||solve([x + y == 3, x == 2*y], x, y)||solve([x + y = 3, x = 2*y], [x, y]);||
||[[# differential-eqn]][#differential-eqn-note differential equation]||DSolve[y'[x] == y[x], y[x], x]||y = Function('y') _
 _
dsolve(Derivative(y(x), x) - y(x), y(x))||y = function('y')(x) _
 _
desolve(diff(y, x) == y, y)||desolve([diff(y(x), x) = y(x)], [y(x)]);||
||[[# differential-eqn-boundary-condition]][#differential-eqn-boundary-condition-note differential equation with boundary condition]||DSolve[{y'[x] == y[x], y[0] == 1}, y[x], x] _
 _
DSolve[{y''[x] == y[x], y[0] == 1, y'[0] == 2}, _
@<&nbsp;&nbsp;>@y[x], x]||##gray|//support for boundary conditions is limited//##||y = function('y')(x) _
 _
##gray|# y(0) = 1:## _
desolve(diff(y, x) == y, y, [0, 1]) _
 _
##gray|# y(0) = 1 and y'(0) = 2:## _
desolve(diff(y, x, x) == y, y, [0, 1, 2])||atvalue(y(x), x=0, 1); _
desolve([diff(y(x), x) = y(x)], [y(x)]);||
||[[# differential-eqns]][#differential-eqns-note differential equations]||eqn1 = x'[t] == x[t] - x[t] * y[t] _
eqn2 = y'[t] == x[t] * y[t] - y[t] _
DSolve[{eqn1, eqn2}, {x[t], y[t]}, t]|| || ||eqn1: diff(x(t), t) = x(t) - x(t) * y(t); _
eqn2: diff(y(t), t) = x(t) * y(t) - y(t); _
desolve([eqn1, eqn2], [x(t), y(t)]);||
||[[# recurrence-eqn]][#recurrence-eqn-note recurrence equation]||eqns = {a[n + 2] == a[n + 1] + a[n], _
@<&nbsp;&nbsp;>@a[0] == 0, _
@<&nbsp;&nbsp;>@a[1] == 1} _
 _
RSolve[eqns, a[n], n] _
 _
##gray|(* remove Fibonacci[] from solution: *)## _
FunctionExpand[RSolve[eqns, a[n], n]]||n = symbols('n') _
a = Function('a') _
eqn = a(n+2) - a(n+1) - a(n) _
 _
rsolve(eqn, a(n), {a(0): 0, a(1): 1})|| ||solve_rec(a[n]=a[n-1]+a[n-2], a[n], a[0] = 0, a[1] = 1);||
||||||||||~ [[# optimization]][#optimization-note optimization]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# minimize]][#minimize-note minimize]||##gray|(* returns list of two items: min value and rule _
@<&nbsp;&nbsp;&nbsp;>@transforming x to argmin *)## _
Minimize[x^2 + 1, x] _
 _
##gray|(* 2 ways to get min value: *)## _
Minimize[x^2 + 1, x][[1]] _
MinValue(x^2 + 1, x] _
 _
##gray|(* 2 ways to get argmin: *)## _
x /. Minimize[x^2 + 1, x][[2]] _
ArgMin[x^2 + 1, x]|| || || ||
||[[# maximize]][#maximize-note maximize]||Maximize[-x^4 + 3 x^3, x] _
 _
Maxvalue[-x^4 + 3 x^3, x] _
ArgMax[-x^4 + 3 x^3, x]|| || || ||
||[[# optimize-unknown-param]][#optimize-unknown-param-note objective with unknown parameter]||##gray|(* minval and argmin are expressions _
@<&nbsp;&nbsp;&nbsp;>@containing a: *)## _
Minimize[(x - a)^2 + x, x]|| || || ||
||[[# unbounded-behavior]][#unbounded-behavior-note unbounded behavior]||##gray|(* MaxValue will be Infinity; MinValue will be _
@<&nbsp;&nbsp;&nbsp;>@-Infinity *)##|| || || ||
||[[# optimize-multiple-var]][#optimize-multiple-var-note multiple variables]||##gray|(* returns one solution: *)## _
Minimize[x^4 - 2 x^2 + 2 y^4 - 3 y^2, {x, y}]|| || || ||
||[[# optimize-constraints]][#optimize-constraints-note constraints]||Minimize[{-x - 2 y^2, y^2 <= 17, 2 x + y <= 5}, _
@<&nbsp;&nbsp;>@{x, y}]|| || || ||
||[[# infeasible-behavior]][#infeasible-behavior-note infeasible behavior]||##gray|(* MaxValue will be -Infinity; MinValue will be _
@<&nbsp;&nbsp;&nbsp;>@Infinity; ArgMax or ArgMin will be _
@<&nbsp;&nbsp;&nbsp;>@Indeterminate *)##|| || || ||
||[[# optimize-int-var]][#optimize-int-var-note integer variables]||Maximize[{x^2 + 2*y, _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@x >= 0, y >= 0, _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@2 x + Pi * y <= 4}, _
@<&nbsp;&nbsp;>@{x, y}, Integers]|| || || ||
||||||||||~ [[# vectors]][#vectors-note vectors]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# vec-literal]][#vec-literal-note vector literal]||##gray|(* row vector is same as array: *)## _
{1, 2, 3}||##gray|# column vector:## _
Matrix([1, 2, 3])||vector([1, 2, 3])||##gray|/* row vector is same as array: */## _
[1, 2, 3];||
||[[# const-vec]][#const-vec-note constant vector] _
 _
##gray|//all zeros, all ones//##||Table[0, {i, 1, 100}] _
Table[1, {i, 1, 100}]||Matrix([0] * 100) _
Matrix([1] * 100)||vector([0] * 100) _
vector([1] * 100)||makelist(0, 100); _
makelist(1, 100);||
||[[# vec-coordinate]][#vec-coordinate-note vector coordinate]||##gray|(* indices start at one: *)## _
{6, 7, 8}[[1]]||Matrix([6, 7, 8])[0]||vector([6, 7, 8])[0]||[6, 7, 8][1];||
||[[# vec-dim]][#vec-dim-note vector dimension] _
@<&nbsp;>@||Length[{1, 2, 3}]||len(Matrix([6, 7, 8])) _
Matrix([6, 7, 8]).shape[0]||len(vector([1, 2, 3]))||length([1, 2, 3]);||
||[[# vec-element-wise]][#vec-element-wise-note element-wise arithmetic operators]||+ - * / _
##gray|//adjacent lists are multiplied element-wise//##||+ - _
 _
##gray|# element-wise multiplication:## _
A = Matrix([1, 2, 3]) _
B = Matrix([2, 3, 4]) _
A.multiply_elementwise(B)||+ -|| + - * /||
||[[# vec-length-mismatch]][#vec-length-mismatch-note vector length mismatch] _
@<&nbsp;>@||##gray|//error//##||##gray|//raises// ShapeError##||##gray|//raises// TypeError##||##gray|//error//##||
||[[# vec-scalar]][#vec-scalar-note scalar multiplication]||3 {1, 2, 3} _
{1, 2, 3} 3 _
##gray|//* may also be used//##||3 * Matrix([1, 2, 3]) _
Matrix([1, 2, 3]) * 3||3 * vector([1, 2, 3]) _
vector([1, 2, 3]) * 3||3 * [1, 2, 3]; _
[1, 2, 3] * 3;||
||[[# vec-dot]][#vec-dot-note dot product]||{1, 1, 1} . {2, 2, 2} _
Dot[{1, 1, 1}, {2, 2, 2}]||v1 = Matrix([1, 1, 1]) _
v2 = Matrix([2, 2, 2]) _
v1.dot(v2)||vector([1, 1, 1]) * vector([2, 2, 2]) _
vector([1,1,1]).dot_product(vector([2,2,2]))||[1, 1, 1] . [2, 2, 2];||
||[[# vec-cross]][#vec-cross-note cross product]||Cross[{1, 0, 0}, {0, 1, 0}]||e1 = Matrix([1, 0, 0]) _
e2 = Matrix([0, 1, 0]) _
e1.cross(e2)||e1 = vector([1, 0, 0]) _
e2 = vector([0, 1, 0]) _
e1.cross_product(e2)|| ||
||[[# vec-norms]][#vec-norms-note norms]||Norm[{1, 2, 3}, 1] _
Norm[{1, 2, 3}] _
Norm[{1, 2, 3}, Infinity]||vec = Matrix([1, 2, 3]) _
 _
vec.norm(1) _
vec.norm() _
vec.norm(inf)||vector([1, 2, 3]).norm(1) _
vector([1, 2, 3]).norm() _
vector([1, 2, 3]).norm(infinity)|| ||
||[[# orthonormal-basis]][#orthonormal-basis-note orthonormal basis]||Orthogonalize[@@{{1, 0, 1}, {1, 1, 1}}@@]|| ||A = matrix([[1, 0, 1], [1, 1, 1]] _
 _
##gray|# Rows of B are orthogonal and span same _
# space as rows of A. 2nd return value _
# expresses rows of A as linear combos _
# of rows of B.## _
B, _ = A.gram_schmidt()||load(eigen); _
 _
gramschmidt([[1, 0, 1], [1, 1, 1]]);||
||||||||||~ [[# matrices]][#matrices-note matrices]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# matrix-literal-ctor]][#matrix-literal-ctor-note literal or constructor]||##gray|(* used a nested array for each row: *)## _
@@{{@@1, 2}, {3, 4@@}}@@ _
 _
##gray|(* display as grid with aligned columns: *)## _
MatrixForm[@@{{@@1, 2}, {3, 4@@}}@@]||Matrix([[1, 2], [3, 4]])||matrix([[1, 2], [3, 4]])||matrix([1, 2], [3, 4]);||
||[[# matrix-from-seq]][#matrix-from-seq-note construct from sequence]||ArrayReshape[{1, 2, 3, 4, 5, 6}, {2, 3}]||Matrix(2, 3, [1, 2, 3, 4, 5, 6])||matrix([1, 2, 3, 4, 5, 6], nrows=2)|| ||
||[[# const-matrices]][#const-matrices-note constant matrices] _
 _
##gray|//all zeros, all ones//##||Table[0, {i, 3}, {j, 3}] _
Table[1, {i, 3}, {j, 3}]||zeros(3, 3) _
ones(3, 3)||matrix([0] * 9, nrows=3) _
matrix([1] * 9, nrows=3)||zeromatrix(3, 3); _
 _
f[i, j] := 1; _
genmatrix(f, 3, 3);||
||[[# diagonal-matrices]][#diagonal-matrices-note diagonal matrices] _
##gray|//and identity//##||DiagonalMatrix[{1, 2, 3}] _
IdentityMatrix[3]||diag(*[1, 2, 3]) _
eye(3)||diag = [1, 2, 3] _
d = {(i, i): v for (i, v) in enumerate(diag)} _
Matrix(3, 3, d) _
 _
matrix.identity(3)||ident(3) * [1, 2, 3]; _
ident(3);||
||[[# matrix-formula]][#matrix-formula-note matrix by formula]||Table[1/(i + j - 1), {i, 1, 3}, {j, 1, 3}]|| ||Matrix(3, 3, lambda i, j: 1/(i + j + 1))||h2[i, j] := 1/(i + j -1); _
genmatrix(h2, 3, 3);||
||[[# matrix-dim]][#matrix-dim-note dimensions]||##gray|(* returns {3, 2}: *)## _
Dimensions[@@{{1, 2}, {3, 4}, {5, 6}}@@]||A = matrix([[1, 2], [3, 4], [5, 6]]) _
 _
##gray|# returns (3, 2):## _
A.shape||A = matrix([[1, 2], [3, 4], [5, 6]]) _
A.nrows() _
A.ncols()||A: matrix([1, 2, 3], [4, 5, 6]); _
matrix_size(A);||
||[[# matrix-elem-lookup]][#matrix-elem-lookup-note element lookup]||##gray|(* top left corner: *)## _
@@{{1, 2}, {3, 4}}@@[[1, 1]]||A = Matrix([[1, 2], [3, 4]]) _
 _
##gray|# top left corner:## _
A[0, 0]||A = matrix([[1, 2], [3, 4]]) _
A[0, 0] _
A[0][0]||A: matrix([1, 2], [3, 4]); _
 _
A[1, 1]; _
A[1][1];||
||[[# extract-matrix-row]][#extract-matrix-row-note extract row]||##gray|(* first row: *)## _
@@{{1, 2}, {3, 4}}@@[[1]]||##gray|# first row:## _
A[0, :]||##gray|# first row as vector:## _
A[0] _
A.rows()[0]||row(matrix([1, 2], [3, 4]), 1); _
matrix([1, 2], [3, 4])[1];||
||[[# extract-matrix-col]][#extract-matrix-col-note extract column]||##gray|(* first column as array: *)## _
@@{{1, 2}, {3, 4}}@@[[All, 1]]||##gray|# first column as 1x2 matrix:## _
A[:, 0]||##gray|# first column as vector:## _
A.columns()[0]||col(matrix([1, 2], [3, 4]), 1);||
||[[# extract-submatrix]][#extract-submatrix-note extract submatrix]||A = @@{{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}@@ _
A[[1;;2, 1;;2]]||rows = [[1, 2, 3], [4, 5, 6], [7, 8, 9]] _
A = Matrix(rows) _
A[0:2, 0:2]||A = matrix(range(1, 10), nrows=3) _
 _
##gray|# takes two lists of indices:## _
A.matrix_from_rows_and_columns([0, 1], [0, 1])|| ||
||[[# matrix-scalar-mult]][#matrix-scalar-mult-note scalar multiplication]||3 * @@{{1, 2}, {3, 4}}@@ _
@@{{1, 2}, {3, 4}}@@ * 3||3 * Matrix([[1, 2], [3, 4]]) _
Matrix([[1, 2], [3, 4]]) * 3||3 * matrix([[1, 2], [3, 4]]) _
matrix([[1, 2], [3, 4]]) * 3||3 * matrix([1, 2], [3, 4]); _
matrix([1, 2], [3, 4]) * 3;||
||[[# matrix-elem-wise-op]][#matrix-elem-wise-op-note element-wise operators]||+ - * / _
##gray|//adjacent matrices are multiplied element-wise//##||+ - _
 _
##gray|# for Hadamard product:## _
A.multiply_elementwise(B)||+ -||+ - * /||
||[[# matrix-mult]][#matrix-mult-note product]||A = @@{{1, 2}, {3, 4}}@@ _
B = @@{{4, 3}, {2, 1}}@@ _
Dot[A, B] _
##gray|(* or use period: *)## _
A . B||A = matrix([[1, 2], [3, 4]]) _
B = matrix([[4, 3], [2, 1]]) _
A * B||A = matrix([[1, 2], [3, 4]]) _
B = matrix([[4, 3], [2, 1]]) _
A * B||A: matrix([1, 2], [3, 4]); _
B: matrix([4, 3], [2, 1]); _
A . B;||
||[[# matrix-vec-mult]][#matrix-vec-mult-note multiply by vector]||@@{{1, 2}, {3, 4}}@@ . {7, 8} _
Dot[@@{{1, 2}, {3, 4}}@@, {5, 6}]|| ||matrix([[1, 2], [3, 4]]) * vector([5, 6])||matrix([1, 2], [3, 4]) . transpose([5, 6]);||
||[[# matrix-power]][#matrix-power-note power]||MatrixPower[@@{{1, 2}, {3, 4}}@@, 3] _
 _
##gray|(* element-wise operator: *)## _
A ^ 3||A @@**@@ 3||A ^ 3 _
A @@**@@ 3||matrix([1, 2], [3, 4]) @@^^@@ 3;||
||[[# matrix-exponential]][#matrix-exponential-note exponential]||MatrixExp[@@{{1, 2}, {3, 4}}@@]|| ||exp(matrix([[1, 2], [3, 4]]))|| ||
||[[# matrix-log]][#matrix-log-note log]||MatrixLog[@@{{1, 2}, {3, 4}}@@]|| || || ||
||[[# kronecker-prod]][#kronecker-prod-note kronecker product]||A = @@{{1, 2}, {3, 4}}@@ _
B = @@{{4, 3}, {2, 1}}@@ _
KroneckerProduct[A, B]|| ||A = matrix([[1, 2], [3, 4]]) _
B = matrix([[4, 3], [2, 1]]) _
A.tensor_product(B)||A: matrix([1, 2], [3, 4]); _
B: matrix([4, 3], [2, 1]); _
kronecker_product(A, B);||
||[[# matrix-norms]][#matrix-norms-note norms]||A = @@{{1, 2}, {3, 4}}@@ _
 _
Norm[A, 1] _
Norm[A, 2] _
Norm[A, Infinity] _
Norm[A, "Frobenius"]|| ||A = matrix([[1, 2], [3, 4]]) _
 _
##gray|# floating point values:## _
A.norm(1) _
A.norm() _
A.norm(infinity) _
A.norm('frob')||A: matrix([1, 2], [3, 4]); _
 _
mat_norm(A, 1); _
##gray|/* none */## _
mat_norm(A, inf); _
mat_norm(A, frobenius);||
||[[# matrix-transpose]][#matrix-transpose-note transpose]||Transpose[@@{{1, 2}, {3, 4}}@@] _
 _
##gray|(* or ESC tr ESC for T exponent notation *)##||A.T||A.transpose()||transpose(A);||
||[[# matrix-conjugate-transpose]][#matrix-conjugate-transpose-note conjugate transpose]||A = @@{{1, I}, {2, -I}}@@ _
ConjugateTranspose[A] _
 _
##gray|(* or ESC ct ESC for dagger exponent notation *)##||M = Matrix([[1, I], [2, -I]]) _
M.adjoint()||M = matrix([[1, I], [2, -I]]) _
M.conjugate_transpose()||ctranspose(matrix([1, %i], [2, -%i]));||
||[[# matrix-inverse]][#matrix-inverse-note inverse]||Inverse[@@{{1, 2}, {3, 4}}@@] _
 _
##gray|(* expression left unevaluated: *)## _
Inverse[@@{{1, 0}, {0, 0}}@@]||A.inv() _
 _
##gray|# raises ValueError:## _
Matrix([[1, 0], [0, 0]]).inv()||A.inverse() _
A ^ -1 _
A ** -1||invert(A); _
A @@^^@@ -1; _
 _
##gray|/* error: */## _
invert(matrix([1, 0], [0, 0]));||
||[[# row-echelon-form]][#row-echelon-form-note row echelon form]||RowReduce[@@{{1, 1}, {1, 1}}@@]|| ||matrix([[1, 1], [1, 1]]).echelon_form()||echelon(matrix([1, 1], [1, 1]));||
||[[# pseudoinverse]][#pseudoinverse-note pseudoinverse]||PseudoInverse[@@{{1, 0}, {3, 0}}@@]|| || || ||
||[[# determinant]][#determinant-note determinant]||Det[@@{{1, 2}, {3, 4}}@@]||A.det()||A.determinant()||determinant(A);||
||[[# trace]][#trace-note trace]||Tr[@@{{1, 2}, {3, 4}}@@]|| ||A.trace()||load("nchrpl"); _
 _
mattrace(matrix([1, 2], [3, 4]));||
||[[# characteristic-polynomial]][#characteristic-polynomial-note characteristic polynomial]||CharacteristicPolynomial[@@{{1, 2}, {3, 4}}@@, x]|| ||matrix([[1, 2], [3, 4]]).charpoly('x')||A: matrix([1, 2], [3, 4]); _
 _
charpoly(A, x);||
||[[# minimal-polynomial]][#minimal-polynomial-note minimal polynomial]|| || ||matrix.identity(3).minpoly('x')||load(diag); _
 _
minimalPoly(jordan(ident(3)));||
||[[# matrix-rank]][#matrix-rank-note rank]||MatrixRank[@@{{1, 1}, {0, 0}}@@]|| ||matrix([[1, 1], [0, 0]]).rank()||rank(matrix([1, 1], [0, 0]));||
||[[# nullspace-basis]][#nullspace-basis-note nullspace basis]||NullSpace[@@{{1, 1}, {0, 0}}@@]|| || ||nullspace(matrix([1, 1], [0, 0]));||
||[[# eigenval]][#eigenval-note eigenvalues]||Eigenvalues[@@{{1, 2}, {3, 4}}@@]||A.eigenvals()||matrix([[1, 2], [3, 4]]).eigenvalues()||##gray|/* returns list of two lists: _
@<&nbsp;&nbsp;&nbsp;>@first is the eigenvalues, _
@<&nbsp;&nbsp;&nbsp;>@second is their multiplicities */## _
eigenvalues(A);||
||[[# eigenvec]][#eigenvec-note eigenvectors]||Eigenvectors[@@{{1, 2}, {3, 4}}@@]||A.eigenvects()||A = matrix([[1, 2], [3, 4]]) _
 _
##gray|# returns list of triples: _
#   (eigenval, eigenvec, multiplicity)## _
A.eigenvectors_right()||##gray|/* returns list of two lists.  The first item is the return value of eigenvalues().  The second item is a list containing a list of eigenvectors for each eigenvalue. */## _
eigenvectors(A);||
||[[# lu-decomposition]][#lu-decomposition-note LU decomposition]||{lu, p, c} = LUDecomposition[@@{{1, 2}, {3, 4}}@@] _
L = LowerTriangularize[lu] _
U = UpperTriangularize[lu] _
P = Permute[IdentityMatrix[2], p]|| ||P, L, U = matrix([[1, 2], [3, 4]]).LU()||A: matrix([1, 2], [3, 4]); _
[P, L, U]: get_lu_factors(lu_factor(A));||
||[[# qr-decomposition]][#qr-decomposition-note QR decomposition]||A := @@{{1, 2}, {3, 4}}@@ _
{Q, R} = QRDecomposition[A] _
A == Q . R|| ||##gray|# numerical result:## _
Q, R = matrix(CDF, [[1, 2], [3, 4]]).QR()|| ||
||[[# spectral-decomposition]][#spectral-decomposition-note spectral decomposition]||A = @@{{1, 2}, {2, 1}}@@ _
z :=  Eigensystem[A] _
d := DiagonalMatrix[z[[1]]] _
P := Transpose[z[[2]]] _
 _
P . d . Inverse[P] == A|| || || ||
||[[# svd]][#svd-note singular value decomposition]||A := @@{{1, 2}, {3, 4}}@@ _
z := SingularValueDecomposition[A] _
U := z[[1]] _
S := z[[2]] _
V := z[[3]] _
 _
N[A] == N[U . S . ConjugateTranspose[V]]|| ||A = matrix(CDF, [[1, 2], [3, 4]]) _
##gray|# numerical result:## _
U, D, V  = A.SVD() _
norm(A - U * D * V.conjugate_transpose())|| ||
||[[# jordan-decomposition]][#jordan-decomposition-note jordan decomposition]||A := @@{{1, 2, 3}, {4, 5, 6}, {7, 8, 9}}@@ _
z := JordanDecomposition[A] _
P := z[[1]] _
J := z[[2]] _
A . P == P . J|| ||A = matrix([[0, 1], [1, 0]]) _
 _
##gray|# eigenvalues must be rational:## _
J, P = A.jordan_form( _
@<&nbsp;&nbsp;>@subdivide=False, transformation=True)|| ||
||[[# polar-decomposition]][#polar-decomposition-note polar decomposition]||A := @@{{1, 2}, {3, 4}}@@ _
{u, s, v} := SingularValueDecomposition[A] _
vt :=  ConjugateTranspose[v] _
 _
U := u * vt _
P =  v * s * vt|| || || ||
||||||||||~ [[# combinatorics]][#combinatorics-note combinatorics]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# factorial]][#factorial-note factorial] _
 _
##gray|//and permutations//##||5! _
Factorial[5] _
 _
Permutations[Range[1, 5]]||factorial(5)||factorial(5) _
5.factorial()||5! _
factorial(5);||
||[[# binomial-coefficient]][#binomial-coefficient-note binomial coefficient] _
 _
##gray|//and combinations//##||Binomial[10, 3]||binomial(10, 3)||binomial(10, 3)||binomial(10, 3);||
||[[# multinomial-coefficient]][#multinomial-coefficient-note multinomial coefficient]||Multinomial[3, 4, 5]|| ||multinomial([3, 4, 5])||multinomial(12, [3, 4, 5]);||
||[[# rising-falling-factorial]][#rising-falling-factorial-note rising and falling factorial]||Pochhammer[1/2, 3] _
 _
FactorialPower[1/2, 3]|| ||rising_factorial(1/2, 3) _
 _
falling_factorial(1/2, 3)||pochhammer(1/2, 3); _
 _
pochhammer(1/2 - 2, 3);||
||[[# subfactorial]][#subfactorial-note subfactorial] _
 _
##gray|//and derangments//##||Needs["Combinatorica@@`@@"] _
 _
NumberOfDerangements[10]||subfactorial(10)||subfactorial(10)|| ||
||[[# int-partitions]][#int-partitions-note integer partitions]||##gray|(* number of partitions: *)## _
PartitionsP[10] _
 _
##gray|(* the partitions as an array: *)## _
IntegerPartitions[10]||from sympy.utilities.iterables \ _
@<&nbsp;&nbsp;>@import partitions _
 _
len(list(partitions(10))) _
 _
[p.copy() for p in partitions(10)]||Partitions(10).cardinality() _
Partitions(10).list()||length(integer_partitions(10)); _
 _
##gray|/* the partitions as an array: */## _
integer_partitions(10); _
 _
||
||[[# compositions]][#compositions-note compositions]||Needs["Combinatorica@@`@@"] _
 _
##gray|(* weak compositions of size 3 is 66: *)## _
NumberOfCompositions[10, 3] _
 _
Compositions[10, 3]|| ||##gray|# compositions of all lengths:## _
Compositions(10).cardinality() _
 _
Compositions(10).list() _
 _
##gray|# of length 3:## _
Compositions(10, min_length=3, _
@<&nbsp;&nbsp;>@max_length=3).list()|| ||
||[[# set-partitions]][#set-partitions-note set partitions]||StirlingS2[10, 3] _
 _
Needs["Combinatorica@@`@@"] _
 _
KSetPartitions[10, 3] _
SetPartititions[10]|| ||stirling_number2(10, 3)||stirling2(10, 3);||
||[[# bell-num]][#bell-num-note bell number]||BellB[10]||bell(10)||bell_number(10)||belln(10);||
||[[# permutations-k-disjoint-cycles]][#permutations-k-disjoint-cyclces permutations with k disjoint cycles]||Abs[StirlingS1[10, 3]]|| ||stirling_number1(10, 3)||abs(stirling1(10, 3));||
||[[# fibonacci-num]][#fibonacci-num-note fibonacci number] _
 _
##gray|//and lucas number//##||Fibonacci[10] _
LucasL[10]||fibonacci(10) _
lucas(10)||fibonacci(10) _
lucas_number2(10, 1, -1)||fib(10); _
lucas(10);||
||[[# bernoulli-num]][#bernoulli-num-note bernoulli number]||BernoulliB[100]||bernoulli(100)||bernoulli(100)||bern(100);||
||[[# harmonic-num]][#harmonic-num-note harmonic number]||HarmonicNumber[100]||harmonic(100)|| || ||
||[[# catalan-num]][#catalan-num-note catalan number]||CatalanNumber[10]||catalan(10)||catalan_number(10)|| ||
||||||||||~ [[# number-theory]][#number-theory-note number theory]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# divisible-test]][#divisible-test-note divisible test] _
@<&nbsp;>@||Divisible[1001, 7]||1001 % 7 == 0||7.divides(1001)||is(mod(1001, 7) = 0);||
||[[# divisors]][#divisors-note divisors]||##gray|(* {1, 2, 4, 5, 10, 20, 25, 50, 100}: *)## _
Divisors[100]||ntheory.divisors(100)||divisors(100)||divisors(100);||
||[[# pseudoprime-test]][#pseudoprime-test-note pseudoprime test]||PrimeQ[7]||ntheory.primetest.isprime(7) _
ntheory.primetest.mr(7, [2, 3])||is_prime(7) _
is_pseudoprime(7)||primep(7);||
||[[# prime-factors]][#prime-factors prime factors]||##gray|(* returns @<{{>@2, 2}, {3, 1}, {7, 1}} *)## _
FactorInteger[84]||##gray|# {2: 2, 3: 1, 7: 1}:## _
ntheory.factorint(84)||##gray|# 2^2 * 3 * 7:## _
factor(84)||##gray|/* 2^2 3 7: */## _
factor(84); _
 _
##gray|/* [[2,2],[3,1],[7,1]]: */## _
ifactors(84);||
||[[# next-prime]][#next-prime-note next prime] _
 _
##gray|//and preceding//##||NextPrime[1000] _
NextPrime[1000, -1]||ntheory.generate.nextprime(1000) _
ntheory.generate.prevprime(1000)||next_prime(1000) _
previous_prime(1000)||next_prime(1000); _
prev_prime(1000);||
||[[# nth-prime]][#nth-prime-note nth prime]||##gray|(* 541: *)## _
Prime[100]||ntheory.generate.prime(100)||primes_first_n(100)[-1]|| ||
||[[# prime-counting-func]][#prime-counting-func-note prime counting function]||##gray|(* 25: *)## _
PrimePi[100]||ntheory.generate.primepi(100)||prime_pi(100)|| ||
||[[# divmod]][#divmod-note divmod] _
@<&nbsp;>@||QuotientRemainder[7, 3]||divmod(7, 3)||divmod(7, 3)||divide(7, 3);||
||[[# gcd]][#gcd-note greatest common divisor] _
 _
##gray|//and relatively prime test//##||GCD[14, 21] _
GCD[14, 21, 777] _
 _
CoprimeQ[14, 21]||gcd(14, 21) _
gcd(gcd(14, 21), 777)||gcd(14, 21) _
gcd(gcd(14, 21), 777)||gcd(14, 21); _
gcd(gcd(14, 21), 777);||
||[[# extended-euclidean-algorithm]][#extended-euclidean-algorithm-note extended euclidean algorithm]||##gray|(* {1, {2, -1}}: *)## _
ExtendedGCD[3, 5]||from sympy.ntheory.modular import igcdex _
 _
##gray|# (2, -1, 1):## _
igcdex(3, 5)||##gray|# (1, 2, -1):## _
xgcd(3, 5)||##gray|/* [2,-1,1]: */## _
gcdex(3, 5);||
||[[# lcm]][#lcm-note least common multiple]||LCM[14, 21]||lcm(14, 21)||lcm(14, 21)||lcm(14, 21);||
||[[# power-mod]][#power-mod-note power modulus]||PowerMod[3, 212, 7]|| ||power_mod(3, 212, 7)|| ||
||[[# mult-inverse]][#mult-inverse-note multiplicative inverse]||##gray|(* inverse of 2 mod 7: *)## _
PowerMod[2, -1, 7] _
 _
##gray|(* left unevaluated: *)## _
PowerMod[2, -1, 4]|| ||r = Integers(7) _
r(2)^-1 _
 _
r2 = Integers(4) _
##gray|# raises ZeroDivisionError:## _
r2(4)^-1|| ||
||[[# chinese-remainder-thm]][#chinese-remainder-thm-note chinese remainder theorem]||##gray|(* returns 173, which is equal to 3 mod 17 and 8 mod 11: *)## _
ChineseRemainder[{3, 8}, {17, 11}]|| ||crt(3, 8, 17, 11)||##gray|/* 173: */## _
chinese([3, 8], [17, 11]);||
||[[# euler-totient]][#euler-totient-note euler totient] _
@<&nbsp;>@||EulerPhi[256]||ntheory.totient(256)||euler_phi(256)||totient(256);||
||[[# carmichael-func]][#carmichael-func-note carmichael function]||CarmichaelLambda[561]|| ||from sage.crypto.util import carmichael_lambda _
 _
carmichael_lambda(561)|| ||
||[[# mult-order]][#mult-order-note multiplicative order]||MultiplicativeOrder[7, 108]|| ||Mod(7, 108).multiplicative_order()|| ||
||[[# primitive-roots]][#primitive-roots-note primitive roots]||PrimitiveRoot[11] _
 _
##gray|(* all primitive roots: *)## _
PrimitiveRootList[11]|| ||primitive_root(11) _
 _
##gray|# raises ValueError if none##|| ||
||[[# discrete-log]][#discrete-log-note discrete logarithm]||##gray|(* solves 10 = 2^x (mod 11): *)## _
MultiplicativeOrder[2, 11, 10]|| ||log(Mod(10, 11), Mod(2, 11))|| ||
||[[# quadratic-residues]][#quadratic-residues-note quadratic residues]||Select[Range[0, 4], KroneckerSymbol[#, 5] == 1 &]|| ||quadratic_residues(5)|| ||
||[[# discrete-sqrt]][#discrete-sqrt-note discrete square root]||PowerMod[4, 1/2, 5]|| ||Mod(4, 5).sqrt()|| ||
||[[# kronecker-symbol]][#kronecker-symbol-note kronecker symbol] _
 _
##gray|//and jacobi symbol//##||KroneckerSymbol[3, 5] _
JacobiSymbol[3, 5]|| ||kronecker_symbol(3, 5)||##gray|//??//## _
jacobi(3, 5);||
||[[# moebius-func]][#moebius-func-note moebius function]||MoebiusMu[11]|| ||moebius(11)||moebius(11);||
||[[# riemann-zeta-func]][#riemann-zeta-func-note riemann zeta function]||Zeta[2]||mpmath.zeta(2)||zeta(2)||zeta(2);||
||[[# continued-fraction]][#continued-fraction-note continued fraction]||##gray|(* {0, 1, 1, 1, 5}: *)## _
ContinuedFraction[11/17] _
 _
##gray|(* arrray of first 100 digits for for pi: *)## _
ca= ContinuedFraction[Pi, 100] _
 _
##gray|(* rational approximation of pi: *)## _
FromContinuedFraction[a]|| ||continued_fraction(11/17) _
 _
continued_fraction(pi, 100)||##gray|/* [0,1,1,1,5]: */## _
cf(11/17); _
 _
float_pi: %pi, numer; _
a = cf(float_pi); _
 _
##gray|/* as continued fraction: */## _
as_cf: cfdisrep(a); _
 _
##gray|/* as simple fraction: */## _
ratsimp(as_cf);||
||[[# convergents]][#convergents-note convergents]||Convergents[11/17] _
 _
##gray|(* for continued fraction: *)## _
Convergents[{0, 1, 1, 1, 5}] _
 _
##gray|(* first 100 rational approximations: *)## _
Convergents[Pi, 100]|| ||##gray|# [0, 1, 1/2, 2/3, 11/17]:## _
continued_fraction(11/17).convergents() _
 _
##gray|# iterable infinite list:## _
continued_fraction(pi, 100).convergents()|| ||
||||||||||~ [[# polynomials]][#polynomials-note polynomials]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# polynomial-literal]][#polynomial-literal-note literal]||p = 2 -3 * x + 2* x^2 _
p2 = (1 + x)^10|| ||p = x^2 - 3*x + 2 _
p2 = (x + 1)^10||p: x^2 - 3*x + 2; _
p2: (x + 1)^10;||
||[[# extract-polynomial-coefficient]][#extract-polynomial-coefficient-note extract coefficient]||Coefficient[(1 + x)^10, x, 3]|| ||p = (1 + x)^10 _
 _
##gray|# coefficients() returns (power, coeff) pairs:## _
[pair[0] for pair in p.coefficients() _
@<&nbsp;>@if pair[1] == 3][0]||coeff(expand((x + 1)^10), x^3); _
 _
coeff(expand((x + 1)^10), x, 3);||
||[[# extract-polynomial-coefficients]][#extract-polynomial-coefficients-note extract coefficients]||CoefficientList[(x + 1)^10, x]|| || ||p: expand((x+1)^10); _
makelist(coeff(p, x^i), i, 0, 10);||
||[[# polynomial-from-coefficient-array]][#polynomial-from-coefficient-array-note from array of coefficients]||a = {2, -3, 1} _
Sum[a[[i]] * x^i, {i, 1, 3}]|| || ||a: [2, -3, 1]; _
sum(x^i * a[i + 1], i, 0, 2);||
||[[# polynomial-degree]][#polynomial-degree-note degree]||Exponent[(x + 1)^10, x]|| || ||hipow(expand((1 + x)^10), x);||
||[[# expand-polynomial]][#expand-polynomial-note expand]||Expand[(1 + x)^5]||expand((1 + x)@@**@@5)||expand((1 + x)^5)||expand((1 + x)^5);||
||[[# factor-polynomial]][#factor-polynomial-note factor]||Factor[3 + 10 x + 9 x^2 + 2 x^3] _
 _
Factor[x^10 - y^10]||factor(3 + 10*x + 9*x@@**@@2 + 2*x@@**@@3)||factor(2*x^3 + 9*x^2 + 10*x + 3)||factor(2*x^3 + 9*x^2 + 10*x + 3);||
||[[# polynomial-roots]][#polynomial-roots-note roots]||Solve[x^3 + 3 x^2 + 2 x - 1 == 0, x] _
 _
##gray|(* just the 2nd root: *)## _
Root[x^3 + 3 x^2 + 2 x - 1, 2]|| || ||solve(x^3 + 3*x^2 + 2*x - 1 = 0, x);||
||[[# polynomial-quotient-remainder]][#polynomial-quotient-remainder-note quotient and remainder]||PolynomialReduce[x^10 - 1, x - 1, {x}]|| || ||[q, r]: divide(x^10-1, x - 1);||
||[[# polynomial-gcd]][#polynomial-gcd-note greatest common divisor]||p1 = -2 - x + 2 x^2 + x^3 _
p2 = 6 - 7 x + x^3 _
PolynomialGCD[p1, p2]|| || ||p1: -2 - x + 2 * x^2 + x^3; _
p2: 6 - 7*x + x^3; _
gcd(p1, p2);||
||[[# polynomial-extended-euclidean-algo]][#polynomial-extended-euclidean-algor-note extended euclidean algorithm]||p1 = -2 - x + 2 x^2 + x^3 _
p2 = 6 - 7 x + x^3 _
 _
##gray|(* returns list; first element is GCD; 2nd element is list of two polynomials *)## _
PolynomialExtendedGCD[p1, p2, x]|| || || ||
||[[# resultant]][#resultant-note resultant]||Resultant[(x-1) * (x-2), (x-3) * (x-3), x]|| || ||resultant((x - 1)*(x - 2), (x - 3)*(x - 3), x);||
||[[# discrimant]][#discriminant-note discriminant]||Discriminant[(x + 1) * (x - 2), x]|| || || ||
||[[# collect-terms]][#collect-terms-note collect terms]||##gray|(* write as polynomial in x: *)## _
Collect[(1 + x + y)^3, x]||collect(expand((x+y+1)**3), x)|| ||load(facexp); _
 _
facsum(expand((1 + x + y)^5), x);||
||[[# multivariate-polynomial-quotient-remainder]][#multivariate-polynomial-quotient-remainder-note multivariate quotient and remainder]||PolynomialReduce[x^10 - y^10, x - y, {x, y}]|| || ||[q, r]: divide(x^10 - y^10, x - y);||
||[[# groebner-basis]][#groebner-basis-note groebner basis]||p1 = x^2 + y + z - 1 _
p2 = x + y^2 + z - 1 _
p3 = x + y + z^2 - 1 _
 _
##gray|(* uses lexographic order by default: *)## _
GroebnerBasis[{p1, p2, p3}, {x, y, z}]|| || || ||
||specify ordering||GroebnerBasis[{p1, p2, p3}, {x, y, z}, _
@<&nbsp;&nbsp;>@MonomialOrder -> DegreeReverseLexicographic] _
 _
##gray|(* possible values for MonomialOrder: _
 _
@<&nbsp;&nbsp;&nbsp;>@Lexicographic _
@<&nbsp;&nbsp;&nbsp;>@DegreeLexicographic _
@<&nbsp;&nbsp;&nbsp;>@EliminationOrder _
@<&nbsp;&nbsp;&nbsp;>@{1, 2, 3} *)##|| || || ||
||elementary symmetric polynomial||SymmetricPolynomial[3, {x1, x2, x3, x4}]|| || || ||
||symmetric reduction||##gray|(* returns list of two elements; 2nd element is remainder if polynomial not symmetric: *)## _
SymmetricReduction[x^3 + y^3 + z^3, {x, y, z}]|| || || ||
||[[# cyclotomic-polynomial]][#cyclotomic-polynomial-note cyclotomic polynomial]||Cyclotomic[10, x]|| || || ||
||[[# hermite-polynomial]][#hermite-polynomial-note hermite polynomial]||HermiteH[4, x]|| || || ||
||[[# chebyshev-polynomial]][#chebyshev-polynomial-note chebyshev polynomial] _
 _
##gray|//first and second kind//##||ChebyshevT[4, x] _
ChebyshevU[4, x]|| || || ||
||interpolation polynomial||pts = Inner[List, {1, 2, 3}, {2, 4, 7}, List] _
InterpolatingPolynomial[pts, x]|| || || ||
||spline|| || || || ||
||[[# partial-fraction-decomposition]][#partial-fraction-decomposition-note partial fraction decomposition]||Apart[(3*x + 2)/ (x^2 + x)] _
 _
##gray|(* can handle multiple vars in denominator: *)## _
Apart[(b * c + a * d)/(b * d)]||apart((3*x+2) / (x*(x+1)))|| ||partfrac((3*x + 2) / (x^2 + x), x);||
||[[# add-fractions]][#add-fractions-note add fractions]||Together[a/b + c/d]||together(x/y + z/w)|| ||ratsimp(a/b + c/d);||
||[[# pade-approximant]][#pade-approximant-note pade approximant]||PadeApproximant[Log[x], {x, 1, {2, 3}}]|| || ||p: taylor(log(x + 1), [x, 0, 5]); _
 _
pade(p, 3, 2);||
||||||||||~ [[# trigonometry]][#trigonometry-note trigonometry]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# trig-eliminate-powers-products]][#trig-eliminate-powers-products-note eliminate powers and products of trigonometric functions]||TrigReduce[Sin[x]^2 + Cos[x] Sin[x]]|| || ||trigreduce(sin(x)^2 + cos(x) * sin(x));||
||[[# trig-eliminate-sums-multiples]][#trig-eliminate-sums-multiples-note eliminate sums and multiples inside trigonometric functions]||TrigExpand[Sin[2 * x + 1]]|| || ||trigexpand(sin(2*x + 1));||
||[[# trig-to-exp]][#trig-to-exp-note trigonometric to exponential]||TrigToExp[Cos[x]]||cos(x).rewrite(cos, exp)|| ||exponentialize(cos(x));||
||[[# exp-to-trig]][#exp-to-trig-note exponential to trigonometric]||ExpToTrig[Exp[I x]]||from sympy import exp, sin, I _
 _
exp(I * x).rewrite(exp, sin)|| ||demoivre(exp(%i * x));||
||[[# fourier-expansion]][#fourier-expansion-note fourier expansion]||##gray|(* in sin and cos: *)## _
FourierTrigSeries[SquareWave[x / (2*Pi)], _
@<&nbsp;&nbsp;>@x, 10] _
 _
##gray|(* in complex exponentials: *)## _
FourierSeries[SquareWave[x / (2*Pi)], x, 10]|| || || ||
||[[# periodic-func]][#periodic-func-note periodic functions on unit interval]||##gray|(*1: [0, 0.5); -1: [0.5, 1.0) *)## _
SquareWave[x] _
 _
##gray|(* 0 at 0 and 0.5; 1 at 0.25; -1 at 0.75 *)## _
TriangleWave[x] _
 _
##gray|(* x on [0, 1) *)## _
SawtoothWave[x]|| || || ||
||[[# fourier-transform]][#fourier-transform-note fourier transform]||f[w_] = FourierTransform[ Sin[t], t, w] _
 _
InverseFourierTransform[f[w], w, t]|| || || ||
||[[# heaviside-step-func]][#heaviside-step-func-note heaviside step function]|| || || || ||
||[[# dirac-delta]][#direct-delta-note dirac delta]|| || || || ||
||||||||||~ [[# special-functions]][#special-functions-note special functions]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# gamma-func]][#gamma-func-note gamma function]||Gamma[1/2]||gamma(Rational(1, 2))||gamma(1/2)||gamma(1/2);||
||[[# err-func]][#err-func-note error function]||Erf[1/2] // N _
 _
Erfc Erfi _
InverseErf InverseErfc||N(erf(Rational(1, 2))) _
 _
erfc erfi||n(erf(1/2))||erf(1/2), numer; _
 _
erfc erfi||
||[[# hyperbolic-func]][#hyperbolic-func-note hyperbolic functions]||Sinh Cosh Tanh _
ArcSinh ArcCosh ArcTanh||sinh cosh tanh _
asinh acosh atanh||sinh cosh tanh _
asinh acosh atanh||sinh cosh tanh _
asinh acosh atanh||
||[[# elliptic-func]][#elliptic-func-note elliptic integerals]||EllipticK _
EllipticF _
EllipticE _
EllipticPi|| || ||elliptic_f _
elliptic_e _
elliptic_pi||
||[[# bessel-func]][#bessel-func-note bessel functions]||BesselJ _
BesselY _
BesselI _
BesselK|| || ||bessel_j _
bessel_y _
bessel_i _
bessel_k||
||||||||||~ [[# permutations]][#permutations-note permutations]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# permutation-from-disjoint-cycles]][#permutation-from-disjoint-cycles-note from disjoint cycles]||p = Cycles[@@{{1, 2}, {3, 4}}@@]||import sympy.combinatorics as comb _
 _
p = combinatorics.Permutation(0, 1)(2, 3)||Permutation([(1, 2), (3, 4)])|| ||
||[[# permutation-to-disjoint-cycles]][#permutation-to-disjoint-cycles-note to disjoint cycles]|| || || || ||
||[[# permutation-from-array]][#permutation-from-array-note from array]||p = PermutationCycles[{2, 1, 4, 3}]||import sympy.combinatorics as comb _
 _
p = combinatorics.Permutation([1, 0, 3, 2])||Permutation((2, 1, 4, 3))|| ||
||[[# permutation-from-two-arrays]][#permutation-from-two-arrays-note from two arrays with same elements]||FindPermutation[{a, b, c}, {b, c, a}]|| || || ||
||[[# permutation-size]][#permutation-size-note size]|| || || || ||
||[[# permutation-support]][#permutation-support-note support] _
 _
##gray|//and fixed points//##||PermutationSupport[Cycles[@@{{1, 3, 5}, {7, 8}}@@]]||import sympy.combinatorics as comb _
 _
p = comb.Permutation(0, 2, 4)(6, 7) _
p.support()|| || ||
||[[# permutation-act-on-element]][#permutation-act-on-element-note act on element]||p = Cycles[@@{{1, 2}, {3, 4}}@@] _
 _
PermutationReplace[1, p]||p(0)||Permutation((2, 1, 4, 3))(1)|| ||
||[[# permutation-act-on-list]][#permutation-act-on-list-note act on list]||##gray|(* if list is too big, extra elements retain _
@<&nbsp;&nbsp;&nbsp;>@their positions; if list is too small, _
@<&nbsp;&nbsp;&nbsp;>@expression is left unevaluated. *)## _
Permute[{a, b, c, d}, p12n34]||import sympy.combinatorics as comb _
  _
p = comb.Permutation(0, 1)(2, 3) _
p([a, b, c, d])||a, b, c, d = var('a b c d') _
 _
p = Permutation([(1, 2), (3, 4)]) _
p.action([a, b, c, d])|| ||
||[[# permutation-compose]][#permutation-compose-note compose]||p1 = Cycles[@@{{1, 2}, {3, 4}}@@] _
p2 = Cycles[@@{{1, 3}}@@] _
PermutationProduct[p1, p2]||import sympy.combinatorics as comb _
 _
p1 = comb.Permutation(0, 1)(2, 3) _
p2 = comb.Permutation(0, 2) _
p1 * p2||p1 = Permutation([(1, 2), (3, 4)]) _
p2 = Permutation((1, 3)) _
p1 * p2|| ||
||[[# permutation-inverse]][#permutation-inverse-note inverse]||InversePermutation[Cycles[@@{{1, 2, 3}}@@]]||import sympy.combinatorics as comb _
 _
comb.Permutation(0, 1, 2) ** -1||Permutation((1, 2, 3)).inverse()|| ||
||[[# permutation-power]][#permutation-power-note power]||PermutationPower[Cycles[@@{{1, 2, 3, 4, 5}}@@], 3]||import sympy.combinatorics as comb _
 _
comb.Permutation(0, 1, 2, 3, 4) ** 3||Permutation((1, 2, 3, 4, 5))^3|| ||
||[[# permutation-order]][#permutation-order-note order]||PermutationOrder[Cycles[@@{{1, 2, 3, 4, 5}}@@]]||import sympy.combinatorics as comb _
 _
comb.Permutation(0, 1, 2, 3, 4).order()||p = Permutation((1,2,3,4,5)) _
p.to_permutation_group_element().order()|| ||
||[[# permutation-num-inversions]][#permutation-num-inversions-note number of inversions]|| ||import sympy.combinatorics as comb _
 _
comb.Permutation(0, 2, 1).inversions()||Permutation((1, 3, 2)).length()|| ||
||[[# permutation-parity]][#permutation-parity-note parity]|| ||import sympy.combinatorics as comb _
 _
comb.Permutation(0, 2, 1).parity()||Permutation((1, 3, 2)).is_even()|| ||
||[[# permutation-to-inversion-vec]][#permutation-to-inversion-vec-note to inversion vector]|| ||import sympy.combinatorics as comb _
 _
comb.Permutation(0, 2, 1).inversion_vector()||Permutation((1, 3, 2)).to_inversion_vector()|| ||
||[[# permutation-from-inversion-vec]][#permutation-from-inversion-vec-note from inversion vector]|| ||import sympy.combinatorics as comb _
 _
comb.Permutation.from_inversion_vector([2, 0])|| || ||
||[[# permutation-list]][#permutation-list-note list permutations]||GroupElements[SymmetricGroup[4]] _
 _
##gray|(* of a list: *)## _
Permutations[{a, b, c, d}]|| ||list(SymmetricGroup(4))|| ||
||[[# permutation-random]][#permutation-random-note random permutation]||RandomPermutation[10]||Permutation.random(10)|| || ||
||||||||||~ [[# descriptive-statistics]][#descriptive-statistics-note descriptive statistics]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# first-moment-stats]][#first-moment-stats-note first moment statistics]||vals = {1, 2, 3, 8, 12, 19} _
X = NormalDistribution[0, 1] _
 _
Mean[vals] _
Total[vals] _
Mean[X]|| || ||load(distrib); _
 _
##gray|/* Other distributions have similar functions: */## _
mean_normal(0, 1);||
||[[# second-moment-stats]][#second-moment-stats-note second moment statistics]||Variance[X] _
StandardDeviation[X]|| || ||load(distrib); _
 _
##gray|/* Other distributions have similar functions: */## _
var_normal(0, 1); _
std_normal(0, 1);||
||[[# second-moment-stats-sample]][#seond-moment-stats-sample-note second moment statistics for samples]||Variance[vals] _
StandardDeviation[vals]|| || || ||
||[[# skewness]][#skewness-note skewness]||Skewness[vals] _
Skewness[X]|| || ||load(distrib); _
 _
##gray|/* Other distributions have similar functions: */## _
skewness_normal(0, 1);||
||[[# kurtosis]][#kurtosis-note kurtosis]||Kurtosis[vals] _
Kurtosis[X]|| || ||load(distrib); _
 _
##gray|/* Other distributions have similar functions: */## _
kurtosis_normal(0, 1);||
||[[# nth-moment]][#nth-moment-note nth moment and nth central moment]||Moment[vals, 5] _
CentralMoment[vals, 5] _
Moment[X, 5] _
CentralMoment[X, 5] _
 _
MomentGeneratingFunction[X, t]|| || || ||
||[[# cumulant]][#cumulant-note cumulant]||Cumulant[vals, 1] _
Cumulant[X, 1] _
 _
CumulantGeneratingFunction[X, t]|| || || ||
||[[# entropy]][#entropy-note entropy] _
@<&nbsp;>@||Entropy[vals]|| || || ||
||[[# mode]][#mode-note mode] _
@<&nbsp;>@||Commonest[{1, 2, 2, 2, 3, 3, 8, 12}]|| || || ||
||[[# quantile-stats]][#quantile-stats-note quantile statistics]||Min[vals] _
Median[vals] _
Max[vals] _
InterquartileRange[vals] _
Quantile[vals, 9/10]|| || ||load(distrib); _
 _
##gray|/* Other distributions have similar functions: */## _
quantile_normal(9/10, 0, 1);||
||[[# bivariate-stats]][#bivariate-stats-note bivariate statistiscs] _
##gray|//correlation, covariance, Spearman's rank//##||Correlation[{1, 2, 3}, {2, 4, 7}] _
Covariance[{1, 2, 3}, {2, 4, 7}] _
SpearmanRho[{1, 2, 3}, {2, 4, 7}]|| || || ||
||[[# freq-table]][#freq-table-note data set to frequency table]||data = {1, 2, 2, 2, 3, 3, 8, 12} _
##gray|(* list of pairs: *)## _
tab = Tally[data] _
##gray|(* dictionary: *)## _
dict = Counts[data]|| || || ||
||[[# invert-freq-table]][#invert-freq-table-note frequency table to data set]||f = Function[a, Table[a[[1]], {i, 1, a[[2]]}]] _
data = Flatten[Map[f, tab]]|| || || ||
||[[# bin]][#bin-note bin]||data = {1.1, 3.7, 8.9, 1.2, 1.9, 4.1} _
##gray|(* bins are [0, 3), [3, 6), and [6, 9): *)## _
bins = BinCounts[data, {{0, 3, 6, 9}}]|| || || ||
||||||||||~ [[# distributions]][#distributions-note distributions]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# binomial]][#binomial-note binomial] _
 _
##gray|//density, cumulative distribution, sample//##||X = BinomialDistribution[100, 1/2] _
 _
PDF[X][50] _
CDF[X][50] _
RandomVariate[X]||from sympy.stats import * _
 _
X = Binomial('X', 100, Rational(1, 2)) _
 _
density(Y).dict[Integer(50)] _
P(X < 50) _
sample(X)|| ||load(distrib); _
 _
pdf_binomial(x, 50, 1/2); _
cdf_binomial(x, 50, 1/2); _
random_binomial(50, 1/2);||
||[[# poisson]][#poisson-note poisson]||X = PoissonDistribution[1]||##gray|# P(X < 4) raises NotImplementedError:## _
X = Poisson('X', 1)|| ||load(distrib); _
 _
pdf_poisson(x, 1); _
cdf_poisson(x, 1); _
random_poisson(1);||
||[[# discrete-uniform]][#discrete-uniform-note discrete uniform]||X = DiscreteUniformDistribution[{0, 99}]||X = DiscreteUniform('X', list(range(0, 100)))|| ||load(distrib); _
 _
##gray|/* {1, 2, ..., 100}: */## _
pdf_discrete_uniform(x, 100); _
cdf_discrete_uniform(x, 100); _
random_discrete_uniform(100);||
||[[# normal]][#normal-note normal] _
 _
##gray|//density, cumulative distribution, quantile, sample//##||X = NormalDistribution[0, 1] _
 _
PDF[X][0] _
CDF[X][0] _
InverseFunction[CDF[X]][1/2] _
RandomVariate[X, 10]||from sympy.stats import * _
 _
X = Normal('X', 0, 1) _
 _
density(X)(0) _
P(X < 0) _
##gray|//??//## _
sample(X)||X = RealDistribution('gaussian', 1) _
 _
X.distribution_function(0) _
X.cum_distribution_function(0) _
X.cum_distribution_function_inv(0.5) _
X.get_random_element()||with(distrib); _
 _
pdf_normal(x, 0, 1); _
cdf_normal(x, 0, 1); _
##gray|/* no inverse cdf */## _
random_normal(0, 1);||
||[[# gamma]][#gamma-note gamma]||X = GammaDistribution[1, 1]||X = Gamma('X', 1, 1)|| ||with(distrib); _
 _
pdf_gamma(x, 1, 1); _
cdf_gamma(x, 1, 1); _
random_gamma(1, 1);||
||[[# exponential]][#exponential-note exponential]||X = ExponentialDistribution[1]||X = Exponential('X', 1)|| ||with(distrib); _
 _
pdf_exponential(x, ); _
cdf_exponential(x, 1); _
random_exponential(1);||
||[[# chi-squared]][#chi-squared-note chi-squared]||X = ChiSquareDistribution[2]||X = ChiSquared('X', 2)||X = RealDistribution('chisquared', 2)||with(distrib); _
 _
pdf_chi2(x, 2); _
cdf_chi2(x, 2); _
random_chi2(2);||
||[[# beta]][#beta-note beta]||X = BetaDistribution[10, 90]||X = Beta('X', 10, 90)||X = RealDistribution('beta', [10, 90])||with(distrib); _
 _
pdf_beta(x, 10, 90); _
cdf_beta(x, 10, 90); _
random_beta(10, 90);||
||[[# uniform]][#uniform-note uniform]||X = UniformDistribution[{0, 1}]||X = Uniform('X', 0, 1)||X = RealDistribution('uniform', [0, 1]) _
 _
X.distribution_function(0.5) _
X.cum_distribution_function(0.5) _
X.cum_distribution_function_inv(0.5) _
X.get_random_element()||with(distrib); _
 _
pdf_continuous_uniform(x, 0, 1); _
cdf_continuous_uniform(x, 0, 1); _
random_continuous_uniform(0, 1);||
||[[# students-t]][#students-t-note student's t]||X = StudentTDistribution[2]||X = StudentT('X', 2)||X = RealDistribution('t', 2)||with(distrib); _
 _
pdf_student_t(x, 2); _
cdf_student_t(x, 2); _
random_student_t(2);||
||[[# snedecors-f]][#snedecors-f-note snedecor's F]||X = FRatioDistribution[1, 1]||X = FDistribution('X', 1, 1)||X = RealDistribution('F', [1, 1])||with(distrib); _
 _
pdf_f(x, 1, 1); _
cdf_f(x, 1, 1); _
random_f(1, 1);||
||[[# empirical-density-func]][#empirical-density-func-note empirical density function]||X = NormalDistribution[0, 1] _
data = Table[RandomVariate[X], {i, 1, 30}] _
Y = EmpiricalDistribution[data] _
PDF[Y]|| || || ||
||[[# empirical-cumulative-distribution]][#empirical-cumulative-distribution-note empirical cumulative distribution]||X = NormalDistribution[0, 1] _
data = Table[RandomVariate[X], {i, 1, 30}] _
Y = EmpiricalDistribution[data] _
Plot[CDF[Y][x], {x, -4, 4}]|| || || ||
||||||||||~ [[# statistical-tests]][#statistical-tests-note statistical tests]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# wilcoxon]][#wilcoxon-note wilcoxon signed-rank test] _
##gray|//variable is symmetric around zero//##||X = UniformDistribution[{-1/2, 1/2}] _
data = RandomVariate[X, 100] _
 _
##gray|(* null hypothesis is true: *)## _
SignedRankTest[data] _
 _
##gray|(* alternative hypothesis is true: *)## _
SignedRankTest[data + 1/2]|| || ||load(distrib); load(stats); _
 _
data: makelist( _
@<&nbsp;&nbsp;>@random_continuous_uniform(-1/2, 1/2), _
@<&nbsp;&nbsp;>@i, 1, 100); _
 _
##gray|/* null hypothesis is true: */## _
test_signed_rank(data); _
 _
##gray|/* alternative hypothesis is true: */## _
test_signed_rank(data + 1/2);||
||[[# kruskal]][#kruskal-note kruskal-wallis rank sum test] _
##gray|//variables have same location parameter//##||X = NormalDistribution[0, 1] _
Y = UniformDistribution[{0, 1}] _
 _
##gray|(* null hypothesis is true: *)## _
LocationEquivalenceTest[ _
@<&nbsp;&nbsp;>@{RandomVariate[X, 100], _
@<&nbsp;&nbsp;&nbsp;>@RandomVariate[X, 200]}] _
 _
##gray|(* alternative hypothesis is true: *)## _
LocationEquivalenceTest[ _
@<&nbsp;&nbsp;>@{RandomVariate[X, 100], _
@<&nbsp;&nbsp;&nbsp;>@RandomVariate[Y, 200]}]|| || ||load(distrib); load(stats); _
 _
x1: makelist( _
@<&nbsp;&nbsp;>@random_normal(0, 1), _
@<&nbsp;&nbsp;>@i, 1, 100); _
x2: makelist( _
@<&nbsp;&nbsp;>@random_normal(0, 1), _
@<&nbsp;&nbsp;>@i, 1, 100); _
y: makelist( _
@<&nbsp;&nbsp;>@random_continuous_uniform(-1/2, 1/2), _
@<&nbsp;&nbsp;>@i, 1, 100); _
 _
##gray|/* null hypothesis is true: */## _
test_rank_sum(x1, x2); _
 _
##gray|/* alternative hypothesis is true: */## _
test_rank_sum(x1, y);||
||[[# kolmogorov-smirnov-test]][#kolmogorov-smirnov-test-note kolmogorov-smirnov test] _
##gray|//variables have same distribution//##||X = NormalDistribution[0, 1] _
Y = UniformDistribution[{-1/2, 1/2}] _
 _
##gray|(* null hypothesis is true: *)## _
KolmogorovSmirnovTest[RandomVariate[X, 200], X] _
 _
##gray|(* alternative hypothesis is true: *)## _
KolmogorovSmirnovTest[RandomVariate[X, 200], Y]|| || || ||
||[[# one-sample-t-test]][#one-sample-t-test-note one-sample t-test] _
##gray|//mean of normal variable with unknown variance is zero//##||X = NormalDistribution[0, 1] _
 _
##gray|(* null hypothesis is true: *)## _
TTest[RandomVariate[X, 200]] _
 _
##gray|(* alternative hypothesis is true: *)## _
TTest[RandomVariate[X, 200] + 1]|| || || ||
||[[# independent-two-sample-t-test]][#independent-two-sample-t-test-note independent two-sample t-test] _
##gray|//two normal variables have same mean//##||X = NormalDistribution[0, 1] _
 _
##gray|(* null hypothesis is true: *)## _
TTest[ _
@<&nbsp;&nbsp;>@{RandomVariate[X, 100], _
@<&nbsp;&nbsp;&nbsp;>@RandomVariate[X, 200]}] _
 _
##gray|(* alternative hypothesis is true: *)## _
TTest[ _
@<&nbsp;&nbsp;>@{RandomVariate[X, 100], _
@<&nbsp;&nbsp;&nbsp;>@RandomVariate[X, 100] + 1}]|| || || ||
||[[# paired-sample-t-test]][#paired-sample-t-test-note paired sample t-test] _
##gray|//population has same mean across measurements//##|| || || || ||
||[[# one-sample-binomial-test]][#one-sample-binomial-test-note one-sample binomial test] _
##gray|//binomial variable parameter are as given//##|| || || || ||
||[[# two-sample-binomial-test]][#two-sample-binomial-test-note two-sample binomial test] _
##gray|//parameters of two binomial variables are equal//##|| || || || ||
||[[# chi-squared-test]][#chi-squared-test-note chi-squared test] _
##gray|//parameters of multinomial variable are all equal//##|| || || || ||
||[[# poisson-test]][#poisson-test-note poisson test] _
##gray|//parameter of poisson variable is as given//##|| || || || ||
||[[# f-test]][#f-test-note F test] _
##gray|//ratio of variance of normal variables are the same//##||X = NormalDistribution[0, 1] _
Y = NormalDistribution[0, 2] _
 _
##gray|(* null hypothesis is true: *)## _
FisherRatioTest[ _
@<&nbsp;&nbsp;>@{RandomVariate[X, 100], _
@<&nbsp;&nbsp;&nbsp;>@RandomVariate[X, 200]}] _
 _
##gray|(* alternative hypothesis is true: *)## _
FisherRatioTest[ _
@<&nbsp;&nbsp;>@{RandomVariate[X, 100], _
@<&nbsp;&nbsp;&nbsp;>@RandomVariate[Y, 100]}]|| || || ||
||[[# pearson-product-moment-test]][#pearson-product-moment-test-note pearson product moment test] _
##gray|//normal variables are not correlated//##||X = NormalDistrubtion[0, 1] _
x = RandomVariate[X, 100] _
y = RandomVariate[X, 100] _
x2 = x + RandomVariate[X, 100] _
data1 = Inner[List, x, y, List] _
data2 = Inner[List, x, x2, List] _
 _
##gray|(* null hypothesis is true: *)## _
CorrelationTest[data1, 0, "PearsonCorrelation"] _
 _
##gray|(* alternative hypothesis is true: *)## _
CorrelationTest[data2, 0, "PearsonCorrelation"]|| || || ||
||[[# spearman-rank-test]][#spearman-rank-test-note spearman rank test] _
##gray|//variables are not correlated//##||X = UniformDistribution[{0, 1}] _
x = RandomVariate[X, 100] _
y = RandomVariate[X, 100] _
x2 = x + RandomVariate[X, 100] _
data1 = Inner[List, x, y, List] _
data2 = Inner[List, x, x2, List] _
 _
##gray|(* null hypothesis is true: *)## _
CorrelationTest[data1, 0, "SpearmanRank"] _
 _
##gray|(* alternative hypothesis is true: *)## _
CorrelationTest[data2, 0, "SpearmanRank"]|| || || ||
||[[# shapiro-wilk-test]][#shapiro-wilk-test-note shapiro-wilk test] _
##gray|//variable has normal distribution//##||X = NormalDistribution[0, 1] _
Y = UniformDistribution[{0, 1}] _
 _
##gray|(* null hypothesis is true: *)## _
ShapiroWilkTest[RandomVariate[X, 100]] _
 _
##gray|(* alternative hypothesis is true: *)## _
ShapiroWilkTest[RandomVariate[Y, 100]]|| || ||load(distrib); load(stats); _
 _
x: makelist( _
@<&nbsp;&nbsp;>@random_normal(0, 1), _
@<&nbsp;&nbsp;>@i, 1, 100); _
y: makelist( _
@<&nbsp;&nbsp;>@random_continuous_uniform(-1/2, 1/2), _
@<&nbsp;&nbsp;>@i, 1, 100); _
 _
##gray|/* null hypothesis is true: */## _
test_normality(x); _
 _
##gray|/* alternative hypothesis is true: */## _
test_normality(y);||
||[[# bartletts-test]][#bartletts-test-note bartlett's test] _
##gray|//two or more normal variables have same variance//##|| || || || ||
||[[# levene-test]][#levene-test-note levene's test] _
##gray|//two or more variables have same variance//##||X = NormalDistribution[0, 1] _
Y = NormalDistribution[0, 2] _
 _
##gray|(* null hypothesis is true: *)## _
LeveneTest[ _
@<&nbsp;&nbsp;>@{RandomVariate[X, 100], _
@<&nbsp;&nbsp;&nbsp;>@RandomVariate[X, 200]}] _
 _
##gray|(* alternative hypothesis is true: *)## _
LeveneTest[ _
@<&nbsp;&nbsp;>@{RandomVariate[X, 100], _
@<&nbsp;&nbsp;&nbsp;>@RandomVariate[Y, 100]}]|| || || ||
||[[# one-way-anova]][#one-way-anova-note one-way anova] _
##gray|//two or more normal variables have same mean//##||Needs["ANOVA`"] _
 _
X = NormalDistribution[0, 1] _
ones = Table[1, {i, 1, 100}] _
x1 = Inner[ _
@<&nbsp;&nbsp;>@List, ones, RandomVariate[X, 100], List] _
x2 = Inner[ _
@<&nbsp;&nbsp;>@List, 2 * ones, RandomVariate[X, 100], List] _
x3 = Inner[ _
@<&nbsp;&nbsp;>@List, 3 * ones, RandomVariate[X, 100], List] _
y = Inner[ _
@<&nbsp;&nbsp;>@List, _
@<&nbsp;&nbsp;>@3 * ones, _
@<&nbsp;&nbsp;>@RandomVariate[X, 100] + 0.5, _
@<&nbsp;&nbsp;>@List] _
 _
##gray|(* null hypothesis is true: *)## _
ANOVA[Join[x1, x2, x3]] _
 _
##gray|(* alternative hypothesis is true: *)## _
ANOVA[Join[x1, x2, y]]|| || || ||
||[[# two-way-anova]][#two-way-anova-note two-way anova]|| || || || ||
||||||||||~ [[# bar-charts]][#bar-charts-note bar charts]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# vertical-bar-chart]][[image http://cdn.hyperpolyglot.org/images/vertical-bar-chart.jpg]] _
[#vertical-bar-chart-note vertical bar chart]||BarChart[{7, 3, 8, 5, 5}, _
@<&nbsp;&nbsp;>@ChartLegends-> _
@<&nbsp;&nbsp;&nbsp;&nbsp;>@{"a","b","c","d","e"}]|| || ||x: [7, 3, 8, 5, 5]; _
labs: [a, b, c, d, e]; _
data: makelist(makelist(labs[i], j, x[i]), i, 5); _
wxbarsplot(flatten(data));||
||[[# horizontal-bar-chart]][[image http://cdn.hyperpolyglot.org/images/horizontal-bar-chart.jpg]] _
[#horizontal-bar-chart-note horizontal bar chart]||BarChart[{7, 3, 8, 5, 5}, BarOrigin -> Left]|| || ||##gray|//none//##||
||[[# grouped-bar-chart]][[image http://cdn.hyperpolyglot.org/images/grouped-bar-chart.jpg]] _
[#grouped-bar-chart-note grouped bar chart]||data = @@{{@@7, 1}, {3, 2}, {8, 1}, {5, 3}, {5, 1@@}}@@ _
BarChart[data]|| || ||x: [7, 3, 8, 5, 5]; _
y: [1,2,1,3,1]; _
labs: [a, b, c, d, e]; _
d1: makelist(makelist(labs[i], j, x[i]), i, 5); _
d2: makelist(makelist(labs[i], j, y[i]), i, 5); _
wxbarsplot(flatten(d1), flatten(d2));||
||[[# stacked-bar-chart]][[image http://cdn.hyperpolyglot.org/images/stacked-bar-chart.jpg]] _
[#stacked-bar-chart-note stacked bar chart]||data = @@{{@@7, 1}, {3, 2}, {8, 1}, {5, 3}, {5, 1@@}}@@ _
BarChart[data, ChartLayout -> "Stacked"]|| || ||x: [7, 3, 8, 5, 5]; _
y: [1,2,1,3,1]; _
labs: [a, b, c, d, e]; _
d1: makelist(makelist(labs[i], j, x[i]), i, 5); _
d2: makelist(makelist(labs[i], j, y[i]), i, 5); _
wxbarsplot(flatten(d1), flatten(d2), _
@<&nbsp;&nbsp;>@grouping=stacked);||
||[[# pie-chart]][[image http://cdn.hyperpolyglot.org/images/pie-chart.jpg]] _
[#pie-chart-note pie chart]||PieChart[{7, 3, 8, 5, 5}]|| || ||x: [7, 3, 8, 5, 5]; _
labs: [a, b, c, d, e]; _
data: makelist(makelist(labs[i], j, x[i]), i, 5); _
wxpiechart(flatten(data));||
||[[# histogram]][[image http://cdn.hyperpolyglot.org/images/histogram.jpg]] _
[#histogram-note histogram]||X = NormalDistribution[0, 1] _
##gray|(* 2nd arg is approx number of bins: *)## _
Histogram[RandomReal[X, 100], 10]|| || ||load(distrib); _
 _
data: makelist(random_normal(0, 1), i, 1, 100); _
wxhistogram(data);||
||[[# box-plot]][[image http://cdn.hyperpolyglot.org/images/box-plot.jpg]] _
[#box-plot-note box plot]||X = NormalDistribution[0, 1] _
n100 = RandomVariate[X, 100] _
BoxWhiskerChart[n100] _
 _
Y = ExponentialDistribution[1] _
e100 = RandomVariate[Y, 100] _
u100 = RandomReal[1, 100] _
data = {n100, e100, u100} _
BoxWhiskerChart[data]|| || ||load(distrib); _
 _
data: makelist(random_normal(0, 1), i, 1, 100); _
wxboxplot(data);||
||||||||||~ [[# scatter-plots]][#scatter-plots-note scatter plots]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# strip-chart]][[image http://cdn.hyperpolyglot.org/images/strip-chart.jpg]] _
[#strip-chart-note strip chart]||X = NormalDistribution[0, 1] _
data = {RandomReal[X], 0} & /@ Range[1, 50] _
ListPlot[data]|| || || ||
||[[# strip-chart-jitter]][[image http://cdn.hyperpolyglot.org/images/strip-chart-jitter.jpg]] _
[#strip-chart-jitter-note strip chart with jitter]||X = NormalDistribution[0, 1] _
Y = UniformDistribution[{-0.05, 0.05}] _
data = {RandomReal[X], RandomReal[Y]} & /@ _
@<&nbsp;&nbsp;>@Range[1, 50] _
ListPlot[data, _
@<&nbsp;&nbsp;>@PlotRange -> {Automatic, {-1, 1}}]|| || || ||
||[[# scatter-plot]][[image http://cdn.hyperpolyglot.org/images/scatter-plot.jpg]] _
[#scatter-plot-note scatter plot]||X = NormalDistribution[0, 1] _
rand = Function[RandomReal[X]] _
data = {rand[], rand[]} & /@ Range[1, 50] _
ListPlot[data]|| || ||load(distrib); _
 _
x: makelist(random_normal(0, 1), i, 1, 50); _
y: makelist(random_normal(0, 1), i, 1, 50); _
wxplot2d([discrete, x, y], [style, points]);||
||[[# additional-point-set]][[image http://cdn.hyperpolyglot.org/images/additional-point-set.jpg]] _
[#additional-point-set-note additional point set]||X = NormalDistribution[0, 1] _
rand = Function[RandomReal[X]] _
data1 = {rand[], rand[]} & /@ Range[1, 50] _
data2 = {rand[]+1, rand[]+1} & /@ Range[1, 50] _
Show[ListPlot[data1], _
@<&nbsp;&nbsp;>@ListPlot[data2, PlotStyle -> Red]]|| || ||load(distrib); _
 _
x1: makelist(random_normal(0, 1), i, 1, 50); _
y1: makelist(random_normal(0, 1), i, 1, 50); _
x2: makelist(random_normal(0, 1), i, 1, 50) + 1; _
y2: makelist(random_normal(0, 1), i, 1, 50); + 1; _
wxplot2d([[discrete, x1, y1], _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@[discrete, x2, y2]], _
@<&nbsp;&nbsp;>@[style, points], [color, black, red]);||
||[[# point-types]][#point-types-note point types]||ListPlot[data, PlotMarkers -> {"*"}] _
 _
##gray|(* shows standard sequence of point types: *)## _
Graphics`PlotMarkers[] _
 _
##gray|(* The elements of the PlotMarkers array can be strings, symbols, expressions, or images. *)##|| || ||wxplot2d([discrete, x, y], _
@<&nbsp;&nbsp;>@[style, points], _
@<&nbsp;&nbsp;>@[point_type, asterisk]); _
 _
##gray|/* possible point_type values: _
 _
@<&nbsp;&nbsp;>@asterisk _
@<&nbsp;&nbsp;>@box _
@<&nbsp;&nbsp;>@bullet _
@<&nbsp;&nbsp;>@circle _
@<&nbsp;&nbsp;>@diamond _
@<&nbsp;&nbsp;>@plus _
@<&nbsp;&nbsp;>@square _
@<&nbsp;&nbsp;>@times _
@<&nbsp;&nbsp;>@triangle _
 _
The bullet and box are filled versions of circle and square. _
*/##||
||[[# point-size]][#point-size-note point size]||X = NormalDistribution[0, 1] _
rand = Function[RandomReal[X]] _
data = {rand[], rand[]} & /@ Range[1, 50] _
##gray|(* point size is fraction of plot width: *)## _
ListPlot[data, PlotStyle -> {PointSize[0.03]}]|| || || ||
||[[# scatter-plot-matrix]][[image http://cdn.hyperpolyglot.org/images/scatter-plot-matrix.jpg]] _
[#scatter-plot-matrix-note scatter plot matrix]||Needs["StatisticalPlots@@`@@"] _
 _
X = NormalDistribution[0, 1] _
x = RandomReal[X, 50] _
y = RandomReal[X, 50] _
z = x + 3 * y _
w = y + RandomReal[X, 50] _
PairwiseScatterPlot[Transpose[{x, y, z, w}]]|| || ||load(distrib); _
 _
x: makelist(random_normal(0, 1), i, 1, 50); _
y: makelist(random_normal(0, 1), i, 1, 50); _
z: x + 3 * y; _
w: y + makelist(random_normal(0, 1), i, 1, 50); _
wxscatterplot(transpose(matrix(x, y, z, w)));||
||[[# scatter-plot-3d]][[image http://cdn.hyperpolyglot.org/images/scatter-plot-3d.jpg]] _
[#scatter-plot-3d-note 3d scatter plot]||X = NormalDistribution[0, 1] _
data = RandomReal[X, {50, 3}] _
ListPointPlot3D[data]|| || ||##gray|//none//##||
||[[# bubble-chart]][[image http://cdn.hyperpolyglot.org/images/bubble-chart.jpg]] _
[#bubble-chart-note bubble chart]||X = NormalDistribution[0, 1] _
data = RandomReal[X, {50, 3}] _
BubbleChart[data]|| || || ||
||[[# linear-regression-line]][[image http://cdn.hyperpolyglot.org/images/linear-regression-line.jpg]] _
[#linear-regression-line-note linear regression line]||data = Table[{i, 2 * i + RandomReal[{-5, 5}]}, _
@<&nbsp;&nbsp;>@{i, 0, 20}] _
model = LinearModelFit[data, x, x] _
Show[ListPlot[data], _
@<&nbsp;&nbsp;>@Plot[model["BestFit"], _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@{x, 0, 20}]]|| || ||load(distrib); _
load(lsquares); _
 _
X: makelist(i, i, 50); _
Y: makelist(X[i] + random_normal(0, 1), i, 50); _
M: transpose(matrix(X, Y)); _
fit: lsquares_estimates(M, [x, y], y = A*x + B, _
@<&nbsp;&nbsp;>@[A, B]); _
A: second(fit[1][1]), numer; _
B: second(fit[1][2]), numer; _
Xhat: makelist(A*X[i] + B, i, 50); _
wxplot2d([[discrete, X, Y], [discrete, X, Xhat]], _
@<&nbsp;&nbsp;>@[style, points, lines], [color, black, red]);||
||[[# q-q-plot]][[image http://cdn.hyperpolyglot.org/images/q-q-plot.jpg]] _
[#q-q-plot-note quantile-quantile plot]||X = NormalDistribution[0, 1] _
data1 = RandomReal[1, 50] _
data2 = RandomReal[X, 50] _
QuantilePlot[data1, data2]|| || ||load(distrib); _
 _
x: makelist(random_continuous_uniform(0, 1), _
@<&nbsp;&nbsp;>@i, 200); _
y: makelist(random_normal(0, 1), i, 200); _
wxplot2d([discrete, sort(x), sort(y)], _
@<&nbsp;&nbsp;>@[style, points]);||
||||||||||~ [[# line-charts]][#line-charts-note line charts]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# polygonal-line-plot]][[image http://cdn.hyperpolyglot.org/images/polygonal-line-plot.jpg]] _
[#polygonal-line-plot-note polygonal line plot]||X = NormalDistribution[0, 1] _
rand = Function[RandomReal[X]] _
f = Function[i, {i, rand[]}] _
data = f /@ Range[1, 20] _
ListLinePlot[data]|| || ||load(distrib); _
 _
x: makelist(random_normal(0, 1), i, 1, 20); _
wxplot2d([discrete, makelist(i, i, 20), x]);||
||[[# additional-line]][[image http://cdn.hyperpolyglot.org/images/additional-line.jpg]] _
[#additional-line-note additional line]||X = NormalDistribution[0, 1] _
data1 = RandomReal[X, 20] _
data2 = RandomReal[X, 20] _
ListLinePlot[{data1, data2} _
@<&nbsp;&nbsp;>@PlotStyle->{Black, Red}]|| || ||load(distrib); _
 _
x: makelist(random_normal(0, 1), i, 1, 20); _
y: makelist(random_normal(0, 1), i, 1, 20); _
wxplot2d([[discrete, makelist(i, i, 20), x], _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@[discrete, makelist(i, i, 20), y]], _
@<&nbsp;&nbsp;>@[color, black, red]);||
||[[# line-types]][#line-types-note line types]||ListLinePlot[data, PlotStyle -> Dashed] _
 _
##gray|(* PlotStyle values: _
 _
@<&nbsp;&nbsp;>@Dashed _
@<&nbsp;&nbsp;>@DotDashed _
@<&nbsp;&nbsp;>@Dotted _
*)##|| || ||##gray|//none//##||
||[[# line-thickness]][#line-thickness-note line thickness]||X = NormalDistribution[0, 1] _
data1 = RandomReal[X, 20] _
data2 = RandomReal[X, 20] _
##gray|(* thickness is fraction of plot width: *)## _
ListLinePlot[{data1, data2}, _
@<&nbsp;&nbsp;>@PlotStyle -> {Thickness[0.01], Thickness[0.02]}]|| || || ||
||[[# function-plot]][[image http://cdn.hyperpolyglot.org/images/function-plot.jpg]] _
[#function-plot-note function plot]||Plot[Sin[x], {x, -4, 4}]|| || ||wxplot2d(sin(x), [x, -4, 4]);||
||[[# parametric-plot]][[image http://cdn.hyperpolyglot.org/images/parametric-plot.jpg]] _
[#parametric-plot-note parametric plot]||ParametricPlot[{Sin[u], Sin[2 * u]}, _
@<&nbsp;&nbsp;>@{u, 0, 2 * Pi}]|| || ||wxplot2d([parametric, sin(t), sin(2*t), _
@<&nbsp;&nbsp;>@[t, 0, 2*%pi]]);||
||[[# implicit-plot]][[image http://cdn.hyperpolyglot.org/images/implicit-plot.jpg]] _
[#implicit-plot-note implicit plot]||ContourPlot[x^2 + y^2 == 1, {x, -1, 1}, _
@<&nbsp;&nbsp;>@{y, -1, 1}]|| || ||load(implicit_plot); _
 _
wximplicit_plot(x^2 + y^2 = 1, [x, -1, 1], _
@<&nbsp;&nbsp;>@[y, -1, 1]);||
||[[# polar-plot]][[image http://cdn.hyperpolyglot.org/images/polar-plot.jpg]] _
[#polar-plot-note polar plot]||PolarPlot[Sin[3 * t], {t, 0, Pi}]|| || ||f(x) := sin(3 * x); _
wxplot2d([parametric, cos(t)*f(t), sin(t)*f(t), _
@<&nbsp;&nbsp;>@[t, 0, %pi]]);||
||[[# cubic-spline]][[image http://cdn.hyperpolyglot.org/images/cubic-spline.jpg]] _
[#cubic-spline-note cubic spline]||X = NormalDistribution[0, 1] _
data = Table[{i, RandomReal[X]}, _
@<&nbsp;&nbsp;>@{i, 0, 20}] _
f = Interpolation[data, _
@<&nbsp;&nbsp;>@InterpolationOrder -> 3] _
Show[ListPlot[data], _
@<&nbsp;&nbsp;>@Plot[f[x], {x, 0, 20}]]|| || ||load(interpol); _
load(distrib); _
load(draw); _
 _
data: makelist([i, random_normal(0, 1)], i, 20); _
cspline(data); _
f(x):=@@''@@%; _
wxdraw2d(explicit(f(x),x,0,20));||
||[[# area-chart]][[image http://cdn.hyperpolyglot.org/images/area-chart.jpg width="75px"]] _
[#area-chart-note area chart]||data = @@{{@@7, 1, 3, 2, 8}, {1, 5, 3, 5, 1@@}}@@ _
stacked = {data[[1]], data[[1]] + data[[2]]} _
ListLinePlot[stacked, Filling -> _
@<&nbsp;&nbsp;>@{1 -> {Axis, LightBlue}, _
@<&nbsp;&nbsp;&nbsp;>@2 -> @@{{@@1}, LightRed}}]|| || || ||
||||||||||~ [[# surface-charts]][#surface-charts-note surface charts]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# contour-plot]][[image http://cdn.hyperpolyglot.org/images/contour-plot.jpg]] _
[#contour-plot-note contour plot]||##gray|(* of function: *)## _
ContourPlot[x * (y - 1), {x, 0, 10}, _
@<&nbsp;&nbsp;>@{y, 0, 10}] _
 _
##gray|(* of data: *)## _
X = NormalDistribution[0, 1] _
rand = Function[RandomReal[X]] _
data = Table[x * (y - 1) + 5 * rand[], _
@<&nbsp;&nbsp;>@{x, 0, 10}, {y, 0, 10}] _
ListContourPlot[data]|| || ||wxcontour_plot(x * (y-1), [x, 0, 10], _
@<&nbsp;&nbsp;>@[y, 0, 10]);||
||[[# heat-map]][[image http://cdn.hyperpolyglot.org/images/heat-map.jpg]] _
[#heat-map-note heat map]||##gray|(* of function: *)## _
DensityPlot[Sin[x] * Sin[y], _
@<&nbsp;&nbsp;>@{x, -4, 4}, _
@<&nbsp;&nbsp;>@{y, -4, 4}] _
 _
##gray|(* of data: *)## _
X = NormalDistribution[0, 1] _
rand = Function[RandomReal[X]] _
data = Table[x * y + 10 * rand[], _
@<&nbsp;&nbsp;>@{x, 1, 10}, _
@<&nbsp;&nbsp;>@{y, 1, 10}] _
ListDensityPlot[data]|| || ||wxplot3d (sin(x) * sin(y), [x,-4,4], [y,-4,4], _
@<&nbsp;&nbsp;>@[elevation, 0], [azimuth, 0], _
@<&nbsp;&nbsp;>@[grid, 100, 100], [mesh_lines_color, false]);||
||[[# shaded-surface-plot]][[image http://cdn.hyperpolyglot.org/images/shaded-surface-plot.jpg]] _
[#shaded-surface-plot-note shaded surface plot]||Plot3D[Exp[-(x^2 + y^2)], {x, -2, 2}, _
@<&nbsp;&nbsp;>@{y, -2, 2}, MeshStyle -> None]|| || || ||
||[[# light-source]][#light-source-note light source]||lot3D[Exp[-(x^2 + y^2)], _
@<&nbsp;&nbsp;>@{x, -2, 2}, {y, -2, 2}, _
@<&nbsp;&nbsp;>@MeshStyle -> None,  _
@<&nbsp;&nbsp;>@Lighting -> @@{{"Point", White, {5, -5, 5}}}@@]|| || || ||
||[[# mesh-surface-plot]][[image http://cdn.hyperpolyglot.org/images/mesh-surface-plot.jpg]] _
[#mesh-surface-plot-note mesh surface plot]||Plot3D[Exp[-(x^2 + y^2)], {x, -2, 2}, _
@<&nbsp;&nbsp;>@{y, -2, 2},  Lighting -> {White}, _
@<&nbsp;&nbsp;>@PlotStyle -> White]|| || ||wxplot3d(exp(-(x^2 + y^2)), _
@<&nbsp;&nbsp;>@[x, -2, 2], [y, -2, 2], _
@<&nbsp;&nbsp;>@[palette, false], [color, black]);||
||[[# view-point]][#view-point-note view point]||##gray|(* (x, y, z) coordinates; _
@<&nbsp;&nbsp;&nbsp;>@(0, 0, 3) is from above: *)## _
Plot3D[Exp[-(x^2 + y^2)], _
@<&nbsp;&nbsp;>@{x, -2, 2}, {y, -2, 2}, _
@<&nbsp;&nbsp;>@MeshStyle -> None, _
@<&nbsp;&nbsp;>@ViewPoint -> {0, 0, 3}]|| || || ||
||[[# vector-field-plot]][[image http://cdn.hyperpolyglot.org/images/vector-field-plot.jpg]] _
[#vector-field-plot-note vector field plot]||StreamPlot[{x^2 + y, 1 + x - y^2}, {x, -4, 4}, {y, -4, 4}]|| || ||plotdf([x^2 + y, 1 + x - y^2], [x, -4, 4], _
@<&nbsp;&nbsp;>@[y, -4, 4]);||
||||||||||~ [[# chart-options]][#chart-options-note chart options]||
||~ ||~ mathematica||~ sympy||~ sage||~ maxima||
||[[# chart-title]][#chart-title-note chart title]||##gray|(* title on top by default *)## _
Plot[Sin[x], {x, -4, 4}, _
@<&nbsp;&nbsp;>@PlotLabel -> "title example"]|| || ||wxplot2d(sin(x), [x, -4, 4], _
@<&nbsp;&nbsp;>@[title, "title example"]); _
 _
data: 1, 1, 2, 2, 3, 3, 3, 3, 4]; _
wxboxplot(data, title="title example"); _
 _
##gray|/* title on top by default */##||
||[[# axis-label]][#axis-label-note axis label]||data = Table[{i, i^2}, {i, 1, 20}] _
ListLinePlot[data, AxesLabel -> {x, x^2}]|| || ||x: makelist(i, i, 20); _
y: makelist(i^2, i, 20); _
wxplot2d([discrete, x, y], _
@<&nbsp;&nbsp;>@[xlabel, "x"], [ylabel, "x^2"]);||
||[[# legend]][[image http://cdn.hyperpolyglot.org/images/legend.jpg]] _
[#legend-note legend]||X = NormalDistribution[0, 1] _
data1 = RandomReal[X, 20] _
data2 = RandomReal[X, 20] _
ListLinePlot[{data1, data2}, _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@PlotLegends -> {"first", "second"}]|| || ||##gray|/* wxplot2d includes a legend by default. _
 _
Provide [legend, false] as argument to suppress it. */##||
||[[# data-label]][#data-label-note data label]||data = @@{{@@313, 3.7}, {62, .094}, {138, 6.6}, _
@<&nbsp;&nbsp;>@{113, 0.76}, {126, 0.15}} _
 _
##gray|(* The {0, -1} argument of Text[] centers the label above the data point. *)## _
Show[ListPlot[data, _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@AxesLabel -> {"pop", "area"}], _
@<&nbsp;&nbsp;>@Graphics[Text["USA", data[[1]], {0, -1}]], _
@<&nbsp;&nbsp;>@Graphics[Text["UK", data[[2]], {0, -1}]],  _
@<&nbsp;&nbsp;>@Graphics[Text["Russia", data[[3]], {0, -1}]],  _
@<&nbsp;&nbsp;>@Graphics[Text["Mexico", data[[4]], {0, -1}]], _
@<&nbsp;&nbsp;>@Graphics[Text["Japan", data[[5]], {0, -1}]]]|| || || ||
||[[# named-colors]][#named-colors-note named colors]||White Gray Black Transparent _
 _
Blue Brown Cyan Green Magenta Orange Pink Purple Red Yellow _
 _
LightBlue LightBrown LightCyan LightGray LightGreen LightMagenta LightOrange LightPink LightPurple LightRed LightYellow|| || ||white gray black _
 _
gray0 gray10 gray100 gray20 gray30 gray40 gray50 gray60 gray70 gray80 gray90 gray100 grey grey0 grey10 grey20 grey30 grey40 grey50 grey60 grey70 grey80 grey90 grey100 _
 _
aquamarine beige blue brown coral cyan forest_green gold goldenrod green khaki magenta medium_blue midnight_blue navy orange orange_red pink plum purple red royalblue salmon sea_green skyblue spring_green turquoise violet yellow _
 _
dark_blue dark_cyan dark_goldenrod dark_gray dark_green dark_grey dark_khaki dark_magenta dark_orange dark_pink dark_red dark_salmon dark_turquoise dark_violet dark_yellow _
 _
light_blue light_coral light_cyan light_goldenrod light_gray light_green light_grey light_magenta light_pink light_red light_salmon light_turquoise light_yellow||
||[[# rgb-color]][#rgb-color-note rgb color]||RGBColor[1, 0, 0] _
##gray|(* with opacity: *)## _
RGBColor[1, 0, 0, 0.5]|| || ||[color, "#FF0000"]||
||[[# background-color]][#background-color-note background color]||Plot[Sin[x], {x, 0, 2 Pi}, _
@<&nbsp;&nbsp;>@Background -> Black, _
@<&nbsp;&nbsp;>@PlotStyle -> White, _
@<&nbsp;&nbsp;>@AxesStyle -> White, _
@<&nbsp;&nbsp;>@TicksStyle -> White, _
@<&nbsp;&nbsp;>@GridLines -> Automatic, _
@<&nbsp;&nbsp;>@GridLinesStyle -> White]|| || || ||
||[[# axis-limits]][#axis-limits-note axis limits]||Plot[x^2, {x, 0, 20}, _
@<&nbsp;&nbsp;>@PlotRange -> @@{{0, 20}, {-200, 500}}@@]|| || || ||
||[[# logarithmic-y-axis]][#logarithmic-y-axis-note logarithmic y-axis]||LogPlot[{x^2, x^3, x^4, x^5}, _
@<&nbsp;&nbsp;>@{x, 0, 20}]|| || ||x: makelist(i, i, 20); _
wxplot2d([ _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@[discrete, x, makelist(i^2, i, 20)], _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@[discrete, x, makelist(i^3, i, 20)]], _
@<&nbsp;&nbsp;>@[logy, true]);||
||[[# aspect-ratio]][#aspect-ratio-note aspect ratio]||##gray|(* aspect ratio is height divided by width: *)## _
Plot[Sin[x], {x, 0, 2 Pi}, AspectRatio -> 0.25] _
 _
##gray|(* In the notebook, dragging the corner of an image increases or decreases the size, but aspect ratio is preserved. *)##|| || ||wxplot2d(sin(x), [x, -4, 4], _
@<&nbsp;&nbsp;>@[yx_ratio, 0.25]); _
 _
##gray|/* Image size can't be changed in notebook. */##||
||[[# ticks]][#ticks-note ticks]||Plot[Sin[x], {x, 0, 2 Pi}, Ticks -> None] _
 _
Plot[Sin[x], {x, 0, 2 Pi}, _
@<&nbsp;&nbsp;>@Ticks -> @@{{0, Pi, 2*Pi}, {-1, 0, 1}}@@]|| || ||wxplot2d(sin(x), [x, -4, 4], _
@<&nbsp;&nbsp;>@[xtics, -4, 2, 4], _
@<&nbsp;&nbsp;>@[ytics, -1, 0.5, 1]);||
||[[# grid-lines]][#grid-lines-note grid lines]||Plot[Sin[x], {x, 0, 2 Pi}, _
@<&nbsp;&nbsp;>@GridLines -> Automatic] _
 _
Plot[Sin[x], {x, 0, 2 Pi}, _
@<&nbsp;&nbsp;>@GridLines -> @@{{@@0, 1, 2, 3, 4, 5, 6}, _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@{-1, -0.5, 0, 0.5, 1}}]|| || || ||
||[[# grid-of-subplots]][[image http://cdn.hyperpolyglot.org/images/subplot-grid.jpg]] _
[#grid-of-subplots-note grid of subplots]||GraphicsGrid[Table[Table[ _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@Histogram[RandomReal[X, 100], 10], _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@{i, 1, 2}], _
@<&nbsp;&nbsp;>@@<&nbsp;&nbsp;>@{j, 1, 2}]]|| || ||load(distrib); _
 _
x: makelist(makelist(random_normal(0, 1), i, 50), _
@<&nbsp;&nbsp;>@j, 4); _
p: makelist(histogram_description(x[i]), i, 4); _
wxdraw(gr2d(p[1]), gr2d(p[2]), gr2d(p[3]), _
@<&nbsp;&nbsp;>@gr2d(p[4]), columns=2);||
||[[# save-plot-as-png]][#save-plot-as-png-note save plot as png]||Export["hist.png", _
@<&nbsp;&nbsp;>@Histogram[RandomReal[X, 100], 10]]|| || ||##gray|//After creating a plot, run// gnuplot //on the// .gnuplot //file generated in the home directory://## _
 _
$ gnuplot maxout.gnuplot||
||~ ||~ ##EFEFEF|@@____________________________________________________@@##||~ ##EFEFEF|@@____________________________________________________@@##||~ ##EFEFEF|@@____________________________________________________@@##||~ ##EFEFEF|@@____________________________________________________@@##||


[[# symbolic-expr-note]]
+ [#symbolic-expr Symbolic Expressions]

In many programming languages, attempting to evaluate an expression with an undefined variable results in an error.  Some languages assign a default value to variables so that such expressions can be evaluated.

In a CAS, undefined variables are treated as unknowns; expressions which contains them are //symbolic expressions//.  When evaluating them, if the unknowns cannot be eliminated, the expression cannot be reduced to a numeric value. The expression then evaluates to a possibly simplified or normalized version of itself.  Symbolic expressions are first class values; they can be stored in variables or passed to functions.

An application of symbolic expressions is a function which solves a system of equations.  Without symbolic expressions, it would be awkward for the caller to specify the equations to be solved.

[[# symbolic-expr-literal-note]]
++ [#symbolic-expr-literal literal]

How to create a symbolic expression.

In most CAS systems, any expression an undefined variables is automatically a a symbolic expression.

**sympy:**

In SymPy, unknowns must be declared.  This is a consequence of SymPy being implemented as a library in a language which throws exceptions when undefined variables are encountered.

[[# prevent-simplification-note]]
++ [#prevent-simplification prevent simplification]

[[# symbolic-expr-var-update-note]]
++ [#symbolic-expr-var-update variable update]

Do symbolic expressions "see" changes to the unknown variables they contain.

[[# symbolic-expr-subst-note]]
++ [#symbolic-expr-subst substitute]

[[# piecewise-symbolic-expr-note]]
++ [#piecewise-symbolic-expr piecewise-defined expression]

[[# simplify-note]]
++ [#simplify simplify]

[[# assumption-note]]
++ [#assumption assumption]

[[# assumption-predicates-note]]
++ [#assumption-predicates assumption predicates]

[[# list-assumptions-note]]
++ [#list-assumptions list assumptions]

[[# rm-assumption-note]]
++ [#rm-assumption remove assumption]

[[# calculus-note]]
+ [#calculus Calculus]

[[# limit-note]]
++ [#limit limit]

[[# limit-at-infinity-note]]
++ [#limit-at-infinity limit at infinity]

[[# one-sided-limit-note]]
++ [#one-sided-limit one-sided limit]

[[# derivative-note]]
++ [#derivative derivative]

[[# derivative-func-note]]
++ [#derivative-func derivative of a function]

[[# derivative-const-note]]
++ [#derivative-const constants]

[[# higher-order-derivative-note]]
++ [#higher-order-derivative higher order derivative]

[[# mixed-partial-derivative-note]]
++ [#mixed-partial-derivative mixed partial derivative]

[[# div-grad-curl-note]]
++ [#div-grad-curl div, grad, and curl]

[[# antiderivative-note]]
++ [#antiderivative antiderivative]

[[# definite-integral-note]]
++ [#definite-integral definite integral]

[[# improper-integral-note]]
++ [#improper-integral improper integral]

[[# double-integral-note]]
++ [#double-integral double integral]

[[# find-poles-note]]
++ [#find-poles find poles]

[[# residue-note]]
++ [#residue residue]

[[# sum-note]]
++ [#sum sum]

[[# series-sum-note]]
++ [#series-sum series sum]

[[# series-expansion-func-note]]
++ [#series-expansion-func series expansion of function]

[[# omitted-order-term-note]]
++ [#omitted-order-term omitted order term]

[[# product-note]]
++ [#product product]

[[# equations-unknowns-note]]
+ [#eqn Equations and Unknowns]

[[# solve-eqn-note]]
++ [#solve-eqn solve equation]

[[# solve-eqns-note]]
++ [#solve-eqns solve equations]

[[# differential-eqn-note]]
++ [#differential-eqn differential equation]

[[# differential-eqn-boundary-condition-note]]
++ [#differential-eqn-boundary-condition differential equation with boundary condition]

[[# differential-eqns-note]]
++ [#differential-eqns differential equations]

[[# recurrence-eqn-note]]
++ [#recurrence-eqn recurrence equation]

[[# optimization-note]]
+ [#optimization Optimization]

An optimization problem consists of a real-valued function called the //objective function//.

The objective function takes one or more //input variables//.  In the case of a maximization problem, the goal is to find the value for the input variables where the objective function achieves its maximum value.  Similarly for a minimization function one looks for the values for which the objective function achieves its minimum value.

[[# minimize-note]]
++ [#minimize minimize]

How to solve a minimization problem in one variable.

[[# maximize-note]]
++ [#maximize maximize]

How to solve a maximization problem.

We can use a function which solves minimization problems to solve maximization problems by negating the objective function.  The downside is we might forget the minimum value returned is the negation of the maximum value we seek.

[[# optimize-unknown-param-note]]
++ [#optimize-unknown-param objective with unknown parameter]

How to solve an optimization when the objective function contains unknown parameters.

[[# unbounded-behavior-note]]
++ [#unbounded-behavior unbounded behavior]

What happens when attempting to solve an unbounded optimization problem.

[[# optimize-multiple-var-note]]
++ [#optimize-multiple-var multiple variables]

How to solve an optimization problem with more than one input variable.

[[# optimize-constraints-note]]
++ [#optimize-constraints constraints]

How to solve an optimization with constraints on the input variable.  The constrains are represented by inequalities.

[[# infeasible-behavior-note]]
++ [#infeasible-behavior infeasible behavior]

What happens when attempting to solve an optimization problem when the solution set for the constraints is empty.

[[# optimize-int-var-note]]
++ [#optimize-int-var integer variables]

How to solve an optimization problem when the input variables are constrained to linear values.

[[# vectors-note]]
+ [#vectors Vectors]

[[# vec-literal-note]]
++ [#vec-literal vector literal]

The notation for a vector literal.

[[# const-vec-note]]
++ [#const-vec constant vector]

How to create a vector with components all the same.

[[# vec-coordinate-note]]
++ [#vec-coordinate vector coordinate]

How to get one of the coordinates of a vector.

[[# vec-dim-note]]
++ [#vec-dim vector dimension]

How to get the number of coordinates of a vector.

[[# vec-element-wise-note]]
++ [#vec-element-wise element-wise arithmetic operators]

How to perform an element-wise arithmetic operation on vectors.

[[# vec-length-mismatch-note]]
++ [#vec-length-mismatch vector length mismatch]

What happens when an element-wise arithmetic operation is performed on vectors of different dimension.

[[# vec-scalar-note]]
++ [#vec-scalar scalar multiplication]

How to multiply a scalar with a vector.

[[# vec-dot-note]]
++ [#vec-dot dot product]

How to compute the dot product of two vectors.

[[# vec-cross-note]]
++ [#vec-cross cross product]

How to compute the cross product of two three-dimensional vectors.

[[# vec-norms-note]]
++ [#vec-norms norms]

How to compute the norm of a vector.

[[# matrices-note]]
+ [#matrices Matrices]

[[# matrix-literal-ctor-note]]
++ [#matrix-literal-ctor literal or constructor]

Literal syntax or constructor for creating a matrix.

**mathematica:**

Matrices are represented as lists of lists.  No error is generated if one of the rows contains too many or two few elements.  The //MatrixQ// predicate can be used to test whether a list of lists is matrix: i.e. all of the sublists contain numbers and are of the same length.

Matrices are displayed by Mathematica using list notation.  To see a matrix as it would be displayed in mathematical notation, use the //MatrixForm// function.

[[# matrix-from-seq-note]]
++ [#matrix-from-seq construct from sequence]

[[# const-matrices-note]]
++ [#const-matrices constant matrices]

[[# diagonal-matrices-note]]
++ [#diagonal-matrices diagonal matrices]

[[# matrix-formula-note]]
++ [#matrix-formula matrix by formula]

[[# matrix-dim-note]]
++ [#matrix-dim dimensions]

How to get the number of rows and columns of a matrix.

[[# matrix-elem-lookup-note]]
++ [#matrix-elem-lookup element lookup]

How to access an element of a matrix.

The anguages described here follow the mathematical convention of putting the row index before the column index.

[[# extract-matrix-row-note]]
++ [#extract-matrix-row extract row]

How to access a row.

[[# extract-matrix-col-note]]
++ [#extract-matrix-col extract column]

How to access a column.

[[# extract-submatrix-note]]
++ [#extract-submatrix extract submatrix]

How to access a submatrix.

[[# matrix-scalar-mult-note]]
++ [#matrix-scalar-mult scalar multiplication]

How to multiply a matrix by a scalar.

[[# matrix-elem-wise-op-note]]
++ [#matrix-elem-wise-op element-wise operators]

Operators which act on two identically sized matrices element by element.  Note that element-wise multiplication of two matrices is used less frequently in mathematics than matrix multiplication.

[[# matrix-mult-note]]
++ [#matrix-mult product]

How to multiply matrices.

Matrix multiplication in non-commutative and only requires that the number of columns of the matrix on the left match the number of rows of the matrix.  Element-wise multiplication, by contrast, is commutative and requires that the dimensions of the two matrices be equal.

[[# matrix-power-note]]
++ [#matrix-power power]

How to compute the power of a square matrix.

For non-negative integers, the power of a matrix is defined recursively with //A^^0^^ = I// and //A^^n^^ = A^^n-1^^  A//.

If the matrix is invertible, the power is defined for negative integers by //A^^n^^ = (A^^-1^^)^^-n^^//.

[[# matrix-exponential-note]]
++ [#matrix-exponential exponential]

[[math]]
\exp(A) = \sum_{i=0}^\infty A^i
[[/math]]

[[# matrix-log-note]]
++ [#matrix-log log]

[[# kronecker-prod-note]]
++ [#kronecker-prod kronecker product]

The [http://en.wikipedia.org/wiki/Kronecker_product Kronecker product] is a non-commutative operation defined on any two matrices.  If A is m x n and B is p x q, then the Kronecker product is a matrix with dimensions mp x nq.

[[# matrix-norms-note]]
++ [#matrix-norms norms]

How to compute the 1-norm, the 2-norm, the infinity norm, and the frobenius norm.

[[# matrix-transpose-note]]
++ [#matrix-transpose transpose]

[[# matrix-conjugate-transpose-note]]
++ [#matrix-conjugate-transpose conjugate transpose]

[[# matrix-inverse-note]]
++ [#matrix-inverse inverse]

[[# row-echelon-form-note]]
++ [#row-echelon-form row echelon form]

[[# pseudoinverse-note]]
++ [#pseudoinverse pseudoinverse]

[[# determinant-note]]
++ [#determinant determinant]

The determinant of a square matrix is equal to the product of the eigenvalues of a matrix.  It is zero if and only if the matrix is nonsingular.

The determinant can be computed by calculating the matrix cofactors along a row or column, multiplying each by the row or column entry, and then summing.  This technique, called Laplace's formula, requires //n!// multiplications, where //n// is number of rows in matrix, and thus is impractical for large matrices.

[[# trace-note]]
++ [#trace trace]

The trace of a matrix is the sum of the diagonal entries.  It is equal to the sum of the eigenvalues of the matrix.

[[# characteristic-polynomial-note]]
++ [#characteristic-polynomial characteristic polynomial]

The charateristic polynomial of a matrix //A// can be defined by:

[[math]]
p(t) = \mathrm{det}(t  I - A)
[[/math]]

The eigenvalues of //A// are the roots of //p(t)//.

[[# minimal-polynomial-note]]
++ [#minimal-polynomial minimal polynomial]

[[# matrix-rank-note]]
++ [#matrix-rank rank]

[[# nullspace-basis-note]]
++ [#nullspace-basis nullspace basis]

[[# eigenval-note]]
++ [#eigenval eigenvalues]

[[# eigenvec-note]]
++ [#eigenvec eigenvectors]

[[# lu-decomposition-note]]
++ [#lu-decomposition LU decomposition]

A factorization into a lower triangular matrix //L//, an upper triangular matrix //U//, and a permutation matrix //P//.  Typically the identity is //PA = LU//.

An LU factorization of a square matrix always exists.  It can be found using a modified variant of Gaussian elimination.  For an //n  n// matrix it requires about //n^^3^^// scalar multiplications.

LU factorization is an efficient way (1) to solve a system of equations, (2) to find the inverse of a matrix, and (3) to compute the determinant of a matrix.

To use //PA = LU// to solve //Ax = b//, first solve for //y// in //Ly = Pb// using forward substitution, then solve for //x// in //Ux = y// using backward substitution.

To use //PA = LU// to find the inverse //B// of //A//, first solve for //Y// in //LU = P// using forward substitution, then solve for //UB = Y// using backward substitution.

The determinant of //A// can be computed from the diagonal entries of //L// and //U//.  To get the sign correctly, one must count the number of row exchanges //S// in the permutation matrix //P//:

[[math]]
(-1)^S \prod_{i=1}^n l_{ii} \prod_{i=1}^n u_{ii}
[[/math]]

[[# qr-decomposition-note]]
++ [#qr-decomposition QR decomposition]

A factorization of a square matrix into an orthogonal matrix //Q// and an upper triangular matrix //R//.

The QR factorization is unique when the original matrix //A// is invertible.

The Gram-Schmidt process can be used to compute a QR factorization, though it is not the most numerically stable method.

If //a,,1,,, ..., a,,n,,// are the column vectors of the original matrix //A//, then the Gram-Schmidt process yields the column vectors //e,,1,,, ..., e,,n,,// of the orthogonal matrix //Q//.

The QR algorithm uses QR factorizations to iteratively find eigenvalues.  For each iteration we perform a QR factorization on A,,k,,:

[[math]]
Q_k R_k = A_k
[[/math]]

Then we multiply Q_k and R_k in reverse to get A,,k+1,,:

[[math]]
A_{k+1} = R_k Q_k
[[/math]]

Usually the sequence of A,,k,, will converge to a triangular matrix with the eigenvalues on the diagonal.  The limit matrix is similar to the original matrix because

[[math]]
A_{k+1} = R_k Q_k = R_k A_k R_k^{-1}
[[/math]]

and hence has the same eigenvalues.

[[# spectral-decomposition-note]]
++ [#spectral-decomposition spectral decomposition]

The spectral decomposition of a square matrix //A// is a factorization //P D  P^^-1^^// where //P// is invertible and //D// is diagonal.

The spectral decomposition is also called the //eigendecomposition//.  The values on the diagonal of //D// are eigenvalues of the matrix //A// and the rows of //P// are eigenvectors.

If a spectral decomposition exists, the matrix //A// is said to be //diagonalizable//.

If an invertible matrix //P// exists such that //A = P  B  P^^-1^^//, then //A// and //B// are said to be //similar//.

According to the spectral theorem, a spectral decomposition exists when the matrix //A// is //normal//, which means it commutes with its conjugate transpose.

If a matrix //A// is symmetric, then a spectral decomposition //P  D  P^^-1^^// exists, and moreover //P// and //D// are real matrices.

[[# svd-note]]
++ [#svd singular value decomposition]

A singluar value decomposition of a matrix //A// is a factorization into a diagonal matrix //S// and unitary matrices //U// and //V// such that //A = U  S  V^^*^^//.

Unlike the spectral decomposition, an SVD always exists, even if //A// is not square.  The values on the diagonal of //S// are called the singular values, and they are the eigenvalues of //A  A^^*^^//.

[[# jordan-decomposition-note]]
++ [#jordan-decomposition jordan decomposition]

The Jordan decomposition of a square matrix //A// is a factorization //A = P  J  P^^-1^^// where //J// is in //Jordan canonical form//.



[[# polar-decomposition-note]]
++ [#polar-decomposition polar decomposition]

A factorization of a square matrix into a unitary matrix //U// and a positive definite Hermitian matrix //P//.

All invertible matrices have a polar decomposition.

A unitary matrix corresponds to a linear transformation representing a rotation, reflection, or a combination of the two.  It is distance perserving, in that it maps vectors to vectors of the same length.  A real valued unitary matrix is called an orthogonal matrix.

[[# combinatorics-note]]
+ [#combinatorics Combinatorics]

Enumerative combinatorics is the study of the size of finite sets.  The sets are defined by some property, and we seek a formula for the size of the set so defined.

For some simple examples, let //A// and //B// be disjoint sets of size //n// and //m// respectively.  The size of the union //A  B// is //n + m// and the size of the Cartesian product //A  B// is //nm//.  The size of the power set of //A// is //2^^n^^//.

[[# factorial-note]]
++ [#factorial factorial]

The factorial function //n!// is the product of the first //n// positive integers //1  2  ...  n//.

It is also the number of permutations or bijective functions on a set of //n// elements.  It is the number of orderings that can be given to //n// elements.

See the section on permutations below for how to iterate through all //n!// permutations on a set of //n// elements.

As the factorial function grows rapidly with //n//, it is useful to be aware of this approximation:

[[math]]
\ln n! \approx n \ln n - n + \frac{1}{2} \ln 2 \pi n
[[/math]]

[[# binomial-coefficient-note]]
++ [#binomial-coefficient binomial coefficient]

A binomial coefficient can be computed using the factorial function:

[[math]]
{n \choose k} = \frac{n!}{(n-k)! k!}
[[/math]]

The binomial coefficient appears in the binomial theorem:

[[math]]
(x+y)^n = \sum_{k=0}^{n} {n \choose k} x^k y^{n-k}
[[/math]]

The binomial cofficient [[$ { n \choose k } $]] is the number of sets of size //k// which can be drawn from a set of size //n// without replacement.

[[# multinomial-coefficient-note]]
++ [#multinomial-coefficient multinomial coefficient]

The multinomial coefficient generalizes the binomial cofficient:

[[math]]
{n \choose k_1, \ldots, k_m} = \frac{n!}{(k_1! \cdots k_m!}
[[/math]]

It appears in the multinomial theorem:

[[math]]
(x_1 + \cdots + x_m)^n = \sum_{k_1 + \cdots + k_m = n} {n \choose k_1, \ldots, k_m} \prod_{t=1}^m x_t^{k_t}
[[/math]]

The multinomial cofficient [[$ { n \choose k_1,ldots,k_m } $]] is the number of ways to partition a set of //n// elements into subsets of size //k,,1,,//, ..., //k,,m,,// where the //k,,i,,// sum to //n//.

[[# rising-falling-factorial-note]]
++ [#rising-falling-factorial rising and falling factorial]

[[# subfactorial-note]]
++ [#subfactorial subfactorial]

A //derangement// is a permutation on a set of //n// elements where every element moves to a new location.

The number of derangements is thus less than the number of permutations, //n!//, and the function for the number of derangements is called the //subfactorial// function.

Using a exclamation point as a prefix to denote the subfactorial, the following equations hold:

[[math]]
!n  = n \cdot [!(n-1)] + (-1)^n
[[/math]]

[[math]]
!n = n! \sum_{i=0}^n \frac{(-1)^i}{i!}
[[/math]]

[[math]]
lim_{n \rightarrow \infty} \frac{!n}{n!} = \frac{1}{e}
[[/math]]

[[# int-partitions-note]]
++ [#int-partitions integer partitions]

The number of multisets of positive integers which sum to a integer.

There are 5 integer partitions of 4:

[[code]]
    4
    3 + 1
    2 + 2
    2 + 1 + 1
    1 + 1 + 1 + 1
[[/code]]

[[# compositions-note]]
++ [#compositions compositions]

The number of sequences of positive integers which sum to an integer.

There are 8 compositions of 4:

[[code]]
    4
    3 + 1
    1 + 3
    2 + 2
    2 + 1 + 1
    1 + 2 + 1
    1 + 1 + 2
    1 + 1 + 1 + 1
[[/code]]

**mathematica:**

The {{NumberOfCompositions}} and {{Compositions}} functions use //weak compositions//, which include zero as a possible summation.

The number of weak compositions of an integer is infinite, since there is no limit on the number of times zero can appear as a summand.  The number of weak compositions of a fixed size is finite, however.

[[# set-partitions-note]]
++ [#set-partitions set partitions]

[[# bell-num-note]]
++ [#set-bell-num bell number]

[[# permutations-k-disjoint-cycles-note]]
++ [#permutations-k-disjoint-cycles permutations with k disjoint cycles]

[[# fibonacci-num-note]]
++ [#fibonacci-num fibonacci number]

[[# bernoulli-num-note]]
++ [#bernoulli-num bernoulli number]

[[# harmonic-num-note]]
++ [#harmonic-num harmonic number]

[[# catalan-num-note]]
++ [#catalan-num catalan number]

[[# number-theory-note]]
+ [#number-theory Number Theory]

[[# divisible-test-note]]
++ [#divisible-test divisible test]

A test whether an integer //a// is divisible by another integer //b//.

Equivalently, does there exists a third integer //m// such that //a = mb//.

[[# divisors-note]]
++ [#divisors divisors]

The list of divisors for an integer.

[[# pseudoprime-test-note]]
++ [#pseudoprime-test pseudoprime test]

A fast primality test.

An integer //p// is prime if for any factorization //p = ab//, where //a// and //b// are integers, either //a// or //b// are in the set {-1, 1}. 


A number of primality tests exists which give occasional false positives.  The simplest of these use Fermat's Little Theorem, in which for prime //p// and //a// in [[$ \{1, ..., p - 1\} $]]:

[[math]]
a^{p-1} \equiv 1 \;(\text{mod}\; p)
[[/math]]

The test for a candidate prime //p// is to randomly choose several values for //a// in  [[$ \{1, ..., p - 1\} $]] and evaluate

[[math]]
a^{p-1} \;(\text{mod}\; p)
[[/math]]

If any of them are not equivalent to 1, then the test shows that p is not prime.  Unfortunately, there are composite numbers //n//, the [https://oeis.org/A002997 Carmichael numbers], for which

[[math]]
a^{n-1} \equiv 1 \;(\text{mod}\; n)
[[/math]]

holds for all //a// in [[$ \{1, ..., n - 1\} $]].

A stronger test is the Miller-Rabin primality test.  Given a candidate prime //n//, we factor //n - 1// as 2^^r^^  //d// where //d// is odd.  If //n// is prime, then one of the following must be true:

[[math]]
a^d \equiv 1 \;(\text{mod}\;n)
[[/math]]

[[math]]
a^{2^r \cdot d} \equiv -1 \;(\text{mod}\;n)
[[/math]]

Thus, one checks the above two equations for a small number of primes.  If we use all primes p  41, then it is known that there are no false positives for n  3  10^^24^^.

Since pseuodoprime tests are known which are correct for all integers up to a very large size, and since conclusively showing that a number is prime is a slow operation for larger integers, a true prime test is often not practical.

[[# prime-factors-note]]
++ [#prime-factors prime factors]

The list of prime factors for an integer, with their multiplicities.

[[# next-prime-note]]
++ [#next-prime next prime]

The smallest prime number greater than an integer.  Also the greatest prime number smaller than an integer.

[[# nth-prime-note]]
++ [#nth-prime nth prime]

The n-th prime number.

[[# prime-counting-func-note]]
++ [#prime-counting-func prime counting function]

The number of primes less than or equal to a value.

According to the prime number theorem:

[[math]]
\lim_{n \rightarrow \infty} \frac{\pi(n)}{n/\log n} = 1
[[/math]]

[[# divmod-note]]
++ [#divmod divmod]

The quotient and remainder.

If the divisor is positive, then the remainder is non-negative.

[[# gcd-note]]
++ [#gcd greatest common divisor]

The greatest common divisor of a pair of integers.  The divisor is always positive.

Two integers are relatively prime if their greatest common divisor is one.

[[# extended-euclidean-algorithm-note]]
++ [#extended-euclidean-algorithm extended euclidean algorithm]

How to express a greatest common divisor as a linear combination of the integers it is a GCD of.

The functions described return the GCD in addition to the coefficients.

[[# lcm-note]]
++ [#lcm least common multiple]

The least common multiple of a pair of integers.

The LCM can be calculated from the GCD using this formula:

[[math]]
\text{lcm}(m, n) = \frac{|m\cdot n|}{\text{gcd}(m, n)}
[[/math]]

[[# power-mod-note]]
++ [#power-mod power modulus]

Raise an integer to a integer power, modulo a third integer.

Euler's theorem can often be used to reduce the size of the exponent.

[[# int-residues-note]]
++ [#int-residues integer residues]

The integer residues or integers modulo //n// are the equivalence classes formed by the relation

[[math]]
a\;(\text{mod}\;n) = b\; (\text{mod}\;n)
[[/math]]

An element in of these equivalence classes is called a representative.  We can extend addition and multiplication to the residues by performing integer addition or multiplication on representatives.  This is well-defined in the sense that it does not depend on the representatives chosen.  Addition and multiplication defined this way turn the integer residues into commutative rings with identity.

[[# mult-inverse-note]]
++ [#mult-inverse multiplicative inverse]

How to get the multiplicative inverse for a residue.

If the representative for a residue is relatively prime to the modulus, then the residue has a multiplicative inverse.  For that matter, if the modulus //n// is a prime, then the ring of residues is a field.

Note that we cannot in general find the inverse using a representative, since the only units in the integers are -1 and 1.

By Euler's theorem, we can find a multiplicative inverse by raising it to the power [[$ \phi(n) - 1 $]]:

[[math]]
a^{\phi(n) - 1} \cdot a = a^{\phi(n)} \equiv 1 \;(\text{mod}\;n)
[[/math]]

When //a// doesn't have a multiplicative inverse, then we cannot cancel it from both sides of a congruence.  The following is true, however:

[[math]]
az \equiv az' \;(\text{mod}\; n) \iff z \equiv z' \;\left(\text{mod}\; \frac{n}{\text{gcd}(a, n)}\right)
[[/math]]

[[# chinese-remainder-thm-note]]
++ [#chinese-remainder-thm chinese remainder theorem]

A function which finds a solution to a system of congruences.

The Chinese remainder theorem asserts that there is a solution //x// to the system of  //k//  congruences

[[math]]
x \equiv a_i \;(\text{mod}\;n_i)
[[/math]]

provided that the //n,,i,,// are pairwise relatively prime.  In this case there are an infinite number of solutions, all which are equal modulo [[$ N = n_1 \cdots n_k $]].  For this reason the solution is returned as a residue modulo //N//.

[[# lift-int-residue-note]]
++ [#lift-int-residue lift integer residue]

How to get a representative from the equivalence class of integers modulo //n//.

Typically an integer in [[$ \{0, ..., n - 1\} $]] is chosen.  A centered lift chooses a representative //x// such that [[$ -n/2 < x \leq n/2 $]].

[[# euler-totient-note]]
++ [#euler-totient euler totient]

The Euler totient function is defined for any positive integer //n// as:

[[math]]
\phi(n) = n \prod_{p | n} \frac{p - 1}{p}
[[/math]]

Note that the product is over the primes that divide //n//.

The Euler totient is the number of integers in [[$ \{1, ..., n - 1\} $]] which are relatively prime to //n//.  It is thus the size of the multiplicative group of integers modulo //n//.

The Euler totient appears in Euler's theorem:

[[math]]
a^{\phi(n)} \equiv 1 \;(\text{mod}\;n)
[[/math]]

[[# carmichael-func-note]]
++ [#carmichael-func carmichael function]

The smallest number //k// such that //a^^k^^  1 (//mod //n)// for all residues //a//.

By Euler's theorem, the Carmichael function (n) is less that or equal to the Euler totient function (n).  The functions are equal when there are primitive roots modulo //n//.

[[# mult-order-note]]
++ [#mult-order multiplicative order]

The multiplicative order of a residue //a// is the smallest exponent //k// such that

[[math]]
a^k \equiv 1\;(\text{mod}\;n)
[[/math]]

In older literature, it is sometimes said that //a// belongs to the exponent //k// modulo //n//.

[[# primitive-roots-note]]
++ [#primitive-roots primitive roots]

A primitive root is a residue module //n// with multiplicative order //(n)//.

The multiplicative group is not necessarily cyclic, though it is when //n// is prime.  If it is not cyclic, then there are no primitive roots.

Any primitive root is a generator for the multiplicative group, so it can be used to find the other primitive roots.

[[# discrete-log-note]]
++ [#discrete-log discrete logarithm]

For a residue //x// and a base residue //b//, find a positive integer such that:

[[math]]
b^k \equiv x\;(\text{mod}\; n)
[[/math]]

[[# quadratic-residues-note]]
++ [#quadratic-residues quadratic residues]

A quadratic residue is a non-zero residue //a// which has a square root modulo //p//.  That is, there is //x// such that

[[math]]
x^2 \equiv a \;(\text{mod}\;p)
[[/math]]

If //a// is non-zero and doesn't have a square root, then it is a quadratic non-residue.

[[# discrete-sqrt-note]]
++ [#discrete-sqrt discrete square root]

How to find the square root of a quadratic residue.

[[# kronecker-symbol-note]]
++ [#kronecker-symbol kronecker symbol]

The Legendre symbol is used to indicate whether a number is a quadratic residue and is defined as follows:

[[math]]
\left( \frac{a}{p} \right)  = \begin{cases} \;\; 1 \;\;\; a \; \text{is a quadratic residue} \\ \;\; 0 \;\;\; p \mid a \\ -1 \;\;\; a \; \text{is a quadratic nonresidue} \end{cases}
[[/math]]

The Legendre symbol is only defined when //p// is an odd prime, but if //n// is an odd positive integer with prime factorization

[[math]]
p_1^{\alpha_1} \ldots p_n^{\alpha_n}
[[/math]]

then the Jacobi symbol is defined as

[[math]]
\left( \frac{a}{n} \right) = \left( \frac{a}{p_1} \right)^{\alpha_1} \ldots \left( \frac{a}{p_n} \right)^{\alpha_n}
[[/math]]

The Kronecker symbol is a generalization of the Jacobi symbol to all integers, but we omit the details.

[[# moebius-func-note]]
++ [#moebius-func moebius function]

The Mbius function //(n)// is 1, -1, or 0 depending upon when //n// is a square-free integer with an even number of prime factors, a square-free integer with an odd number of prime factors, or an integer which is divisible by //p^^2^^// for some prime //p//.

The Mbius function is multiplicative: when //a// and //b// are relatively prime, //(a)(b) = (ab)//.

The Mbius function appears in the Mbius inversion formula.  If //g// and //f// are possibly complex-valued functions defined on the natural numbers such that for all integers n  1:

[[math]]
g(n) = \sum_{d | n} f(d)
[[/math]]

then for all integers n  1:

[[math]]
f(n) = \sum_{d | n} \mu(d) g(n | d)
[[/math]]

[[# riemann-zeta-func-note]]
++ [#riemann-zeta-func riemann zeta function]

The Riemann zeta function is a complex-valued function defined as the analytic continuation of this series:

[[math]]
\zeta(s) = \sum_{n=1}^\infty \frac{1}{n^s}
[[/math]]

The function has zeros (called the trivial zeros) at -2, -4, ....  All other zeros must lie in the strip 0  (z)  1.  In 1859 Riemann conjectured that all non-trivial zeros are on the line (z) = 1/2.

[[# continued-fraction-note]]
++ [#continued-fraction continued fraction]

Convert a real number to a continued fraction.

A continued fraction is a sequence of integers //a,,0,,, a,,1,,, ..., a,,n,,// representing the fraction:

[[math]]
a_0 + \frac{1}{a_1 + \frac{1}{a_2 + \frac{1}{\ddots + {\frac{1}{a_n}}}}} 
[[/math]]

The sequence can even be infinite, in which case the fraction is the limit of the rational numbers defined by taking the first //n// digits in the sequence.

A continued fraction for a real number can be computed using the Euclidean algorithm.  In the case of a rational number, one starts with the numerator and the denominator.  In the case of a rational number, one can start with the number itself and 1.

A continued fraction is finite if and only if the number is a rational.

A continued fraction repeats if and only if it is a quadratic irrational.

[[# convergents-note]]
++ [#convergents convergents]

The first //n// digits of a continued fraction define a sequence of rational numbers called the //convergents//.    The rational numbers converge to the number defined by the continued fraction.

Each convergent //r/q// is the closest rational number to the continued fraction with denominator of size //q// or smaller.

[[# polynomials-note]]
+ [#polynomials Polynomials]

[[# polynomial-literal-note]]
++ [#polynomial-literal literal]

[[# extract-polynomial-coefficient-note]]
++ [#extract-polynomial-coefficient extract coefficient]

[[# extract-polynomial-coefficients-note]]
++ [#extract-polynomial-coefficients extract coefficients]

[[# polynomial-from-coefficient-array-note]]
++ [#polynomial-from-coefficient-array from array of coefficients]

[[# polynomial-degree-note]]
++ [#polynomial-degree degree]

[[# expand-polynomial-note]]
++ [#expand-polynomial expand]

[[# factor-polynomial-note]]
++ [#factor-polynomial factor]

[[ #collect-terms-note]]
++ [#collect-terms collect terms]

[[# polynomial-roots-note]]
++ [#polynomial-root roots]

[[# polynomial-quotient-remainder-note]]
++ [#polynomial-quotient-remainder quotient and remainder]

[[# polynomial-gcd-note]]
++ [#polynomial-gcd greatest common divisor]

++ extended euclidean algorithm

++ resultant

++ discriminant

++ groebner basis

++ specify ordering

++ elementary symmetric polynomial

++ symmetric reduction

[[# cyclotomic-polynomial-note]]
++ [#cyclotomic-polynomial cyclotomic polynomial]

[[# hermite-polynomial-note]]
++ [#hermite-polynomial hermite polynomial]

[[# chebyshev-polynomial-note]]
++ [#chebyshev-polynomial chebyshev polynomial]

++ interpolation polynomial

++ spline

[[# add-fractions-note]]
++ [#add-fractions add fractions]

[[# partial-fraction-decomposition-note]]
++ [#parial-fraction-decomposition partial fraction decomposition]

[[# pade-approximant-note]]
++ [#pade-approximant pade approximant]

[[# trigonometry-note]]
+ [#trigonometry Trigonometry]

[[# trig-eliminate-powers-products-note]]
++ [#trig-eliminate-powers-products eliminate powers and products of trigonometric functions]

[[# trig-eliminate-sums-multiples-note]]
++ [#trig-eliminate-sums-multiples eliminate sums and multiples inside trigonometric functions]

[[# trig-to-exp-note]]
++ [#trig-to-exp trigonometric to exponential]

[[# exp-to-trig-note]]
++ [#exp-to-trig exponential to trigonometric]

[[# fourier-expansion-note]]
++ [#fourier-expansion fourier expansion]

[[# periodic-func-note]]
++ [#periodic-func periodic functions on unit interval]

[[# fourier-transform-note]]
++ [#fourier-transform fourier transform]

[[# heaviside-step-func-note]]
++ [#heaviside-step-func heaviside step function]

[[# dirac-delta-note]]
++ [#dirac-delta dirac delta]

[[# special-functions-note]]
+ [#special-functions Special Functions]

[[# gamma-func-note]]
++ [#gamma-func gamma function]

The gamma function is defined for all complex numbers except the non-positive integers.

For positive integers, the following equation holds:

[[math]]
\Gamma(n) = (n-1)!
[[/math]]

If the real part of //t// is positive, then

[[math]]
\Gamma(t) = \int_0^\infty x^{t-1} e^{-x} dx
[[/math]]

[[# err-func-note]]
++ [#err-func error function]

The error function is function from  to [-1, 1] defined by:

[[math]]
\mathrm{erf}(x) = \frac{2}{\sqrt(\pi)} \int_0^x e^{-t^2} dt
[[/math]]

The complementary error function is

[[math]]
\mathrm{erfc}(x) = 1 - erf(x)
[[/math]]

The cumulative distribution of the standard normal distribution is related to the error function by scaling:

[[math]]
\Phi(x) = \frac{1}{2} + \frac{1}{2} \mathrm{erf}(\frac{x}{\sqrt(2)}) = \frac{1}{2} \mathrm{erfc}(\frac{-x}{\sqrt(2)})
[[/math]]


[[# hyperbolic-func-note]]
++ [#hyperbolic-func hyperbolic functions]

Definitions of the hyperbolic functions:

[[math]]
\mathrm{sinh}\;x = \frac{e^x - e^{-x}}{2}
[[/math]]

[[math]]
\mathrm{cosh}\;x = \frac{e^x + e^{-x}}{2}
[[/math]]

[[math]]
\mathrm{tanh}\;x = \frac{\mathrm{sinh}\;x}{\mathrm{cosh}\;x}
[[/math]]

{{sinh}} and {{cosh}} are odd and even functions, respectively.  Like e^^x^^ and e^^-x^^, {{sinh}} and {{cosh}} span the linear space of solutions to {{y''(x) = y(x)}}.

[[# elliptic-func-note]]
++ [#elliptic-func elliptic functions]

[[# bessel-func-note]]
++ [#bessel-func bessel functions]

[[# permutations-note]]
+ [#permutations Permutations]

A permutation is a bijection on a set of //n// elements.

The notation that Mathematica uses assumes the set the permutation operates on is indexed by {1, .., n}.  The notation that SymPy uses assumes the set is indexed by {0, ..., n - 1}.

//Cayley two line notation//

//one line notation//

//cycle notation//

//inversions//

[[# permutation-from-disjoint-cycles-note]]
++ [#permutation-from-disjoint-cycles from disjoint cycles]

[[# permutation-to-disjoint-cycles-note]]
++ [#permutation-to-disjoint-cycles to disjoint cycles]

[[# permutation-from-array-note]]
++ [#permutation-from-array from array]

[[# permutation-from-two-arrays-note]]
++ [#permutation-from-two-arrays from two arrays with same elements]

[[# permutation-size-note]]
++ [#permutation-size size]

[[# permutation-support-note]]
++ [#permutation-support support]

[[# permutation-act-on-element-note]]
++ [#permutation-act-on-element act on element]

[[# permutation-act-on-list-note]]
++ [#permutation-act-on-list act on list]

[[# permutation-compose-note]]
++ [#permutation-compose compose]

[[# permutation-inverse-note]]
++ [#permutation-inverse inverse]

[[# permutation-power-note]]
++ [#permutation-power power]

[[# permutation-order-note]]
++ [#permutation-order order]

[[# permutation-num-inversions-note]]
++ [#permutation-num-inversions number of inversions]

[[# permutation-parity-note]]
++ [#permutation-parity parity]

Permutations are classified as even or odd based on the number of inversions.

The composition of two even permutations is even.

[[# permutation-to-inversion-vec-note]]
++ [#permutation-to-inversion-vec to inversion vector]

[[# permutation-from-inversion-vec-note]]
++ [#permutation-from-inversion-vec from inversion vector]

[[# permutation-list-note]]
++ [#permutation-list list permutations]

[[# permutation-random-note]]
++ [#permutation-random random permutation]

[[# descriptive-statistics-note]]
+ [#descriptive-statistics Descriptive Statistics]

[[# distributions-note]]
+ [#distributions Distributions]

[[# statistical-tests-note]]
+ [#statistical-tests Statistical Tests]

A selection of statistical tests.  For each test the null hypothesis of the test is stated in the left column.

In a null hypothesis test one considers the //p-value//, which is the chance of getting data which is as or more extreme than the observed data if the null hypothesis is true.  The null hypothesis is usually a supposition that the data is drawn from a distribution with certain parameters.

The extremeness of the data is determined by comparing the expected value of a parameter according to the null hypothesis to the estimated value from the data.  Usually the parameter is a mean or variance.  In a //one-tailed test// the p-value is the chance the difference is greater than the observed amount; in a //two-tailed test// the p-value is the chance the absolute value of the difference is greater than the observed amount. 

[[# wilcoxon-note]]
++ [#wilcoxon wilcoxon signed-rank test]

A non-parametric est whether a variable is drawn from a distribution that is symmetric about zero.

Often this test is used to test that the mean of the distribution is zero.

[[# kruskal-note]]
++ [#kruskal kruskal-wallis rank sum test]

A non-parametric test whether variables have the same mean.

For two variables, this test is the same as the Mann-Whitney test.

**maxima:**

The Maxima function only supports testing two variables.

[[# kolmogorov-smirnov-test-note]]
++ [#kolmogorov-smirnov-test kolmogorov-smirnov test]

Test whether two samples are drawn from the same distribution.

[[# one-sample-t-test-note]]
++ [#one-sample-t-test one-sample t-test]

Student's t-test determines whether a sample drawn from a normal distribution has mean zero.

The test can be used to test for a different mean value; just subtract the value from each value in the sample.

One may know in advance that the sample is drawn from a normal distribution.  For example, if the values in the sample are each means of large samples, then the distribution is normal by the central limit theorem.

The Shapiro-Wilk test can be applied to determine if the values come from a normal distribution.

If the distribution is not known to be normal, the Wilcoxon signed-rank test can be used instead.

The Student's t-test used the sample to estimate the variance, and as a result the test statistic has a t-distribution.

By way of contrast, the z-test assumes that the variance is known in advance, and simply scales the data to get a z-score, which has standard normal distribution.

[[# independent-two-sample-t-test-note]]
++ [#independent-two-sample-t-test independent two-sample t-test]

Test whether two normal variables have same mean.

[[# paired-sample-t-test-note]]
++ [#paired-t-test paired sample t-test]

A t-test used when the same individuals are measure twice.

[[# one-sample-binomial-test-note]]
++ [#one-sample-binomial-test one-sample binomial test]

[[# two-sample-binomial-test-note]]
++ [#two-sample-binomial-test two-sample binomial test]

[[# chi-squared-test-note]]
++ [#chi-squared-test chi-squared test]

[[# poisson-test-note]]
++ [#poisson-test poisson test]

[[# f-test-note]]
++ [#f-test F test]

[[# pearson-product-moment-test-note]]
++ [#pearson-product-moment-test pearson product moment test]

[[# spearman-rank-test-note]]
++ [#spearman-rank-test pearson spearman rank test]

[[# shapiro-wilk-test-note]]
++ [#shapiro-wilk-test shapiro-wilk test]

[[# bartletts-test-note]]
++ [#bartletts-test bartlett's test]

A test whether variables are drawn from normal distributions with the same variance.

[[# levene-test-note]]
++ [#levene-test levene's test]

A test whether variables are drawn from distributions with the same variance.

[[# one-way-anova-note]]
++ [#one-way-anova one-way anova]

[[# two-way-anova-note]]
++ [#two-way-anova two-way anova]

[[# bar-charts-note]]
+ [#bar-charts Bar Charts]

[[# vertical-bar-chart-note]]
++ [#vertical-bar-chart vertical bar chart]

A chart in which the height of bars is used to represent a list of numbers.

**maxima:**

Maxima plots the frequency of the values, and not the values themselves.  Non-positive values cannot be represented.

[[# horizontal-bar-chart-note]]
++ [#horizontal-bar-chart horizontal bar chart]

A bar chart in which zero is the y-axis and the bars extend to the right.

[[# grouped-bar-chart-note]]
++ [#grouped-bar-chart grouped bar chart]

[[# stacked-bar-chart-note]]
++ [#stacked-bar-chart stacked bar chart]

[[# pie-chart-note]]
++ [#pie-chart pie chart]

**maxima:**

Note that Maxima plots the frequency of the values, and not the values themselves.

[[# histogram-note]]
++ [#histogram histogram]

A histogram is a bar chart in which each bar represents the frequency of values in a data set within a range.  The width of the bars can be used to indicate the ranges.

[[# box-plot-note]]
++ [#box-plot box plot]

[[# scatter-plots-note]]
+ [#scatter-plots Scatter Plots]

[[# strip-chart-note]]
++ [#strip-chart strip chart]

A strip chart represents a list of values by points on a line. The values are converted to pairs by assigning the y-coordinate a constant value of zero.  Pairs are then displayed with a scatter plot.

[[# strip-chart-jitter-note]]
++ [#strip-chart-jitter strip chart with jitter]

A strip chart in which in which a random variable with small range is used to fill the y-coordinate. Jitter makes it easier to see how many values are in dense regions.

[[# scatter-plot-note]]
++ [#scatter-plot scatter plot]

How to plot a list of pairs of numbers by representing the pairs as points in the (x, y) plane.

[[# additional-point-set-note]]
++ [#additional-point-set additional point set]

How to add a second list of pairs of numbers to a scatter plot.  Color can be used to distinguish the two data sets.

[[# point-types-note]]
++ [#point-types point types]

How to select the symbols used to mark data points.  Choice of symbols can be use to distinguish data sets.

[[# point-size-note]]
++ [#point-size point size]

How to change the size of the symbols used to mark points.

[[# scatter-plot-matrix-note]]
++ [#scatter-plot-matrix scatter plot matrix]

A scatter plot matrix is a way of displaying a multivariate data set by means of a grid of scatter plots.  Off-diagonal plots are scatter plots of two of the variables.  On-diagonal plots can be used to to display the name or a histogram of one of the variables.

[[# scatter-plot-3d-note]]
++ [#scatter-plot-3d 3d scatter plot]

How to represent a list of triples of numbers by points in (x, y, z) space.

[[# bubble-chart-note]]
++ [#bubble-chart bubble chart]

How to represent a list of triples of numbers by position in the (x, y) plane and size of the point marker.

It is probably better to associate the 3rd component of each triple with the //area//, and not the //diameter// of the point marker, but in general bubble charts suffer from ambiguity.

[[# linear-regression-line-note]]
++ [#linear-regression-line linear regression line]

How to add a linear regression line to a scatter plot.

[[# q-q-plot-note]]
++ [#q-q-plot quantile-quantile plot]

[[# line-charts-note]]
+ [#line-charts Line Charts]

[[# polygonal-line-plot-note]]
++ [#polygonal-line-plot polygonal line plot]

[[# additional-line-note]]
++ [#additional-line additional line]

[[# line-types-note]]
++ [#line-types line types]

[[# line-thickness-note]]
++ [#line-thickness line thickness]

[[# function-plot-note]]
++ [#function-plot function plot]

[[# parametric-plot-note]]
++ [#parametric-plot parametric plot]

[[# implicit-plot-note]]
++ [#implicit-plot implicit plot]

[[# polar-plot-note]]
++ [#polar-plot polar plot]

[[# cubic-spline-note]]
++ [#cubic-spline cubic spline]

[[# area-chart-note]]
++ [#area-chart area chart]

[[# surface-charts-note]]
+ [#surface-charts Surface Charts]

[[# contour-plot-note]]
++ [#contour-plot contour plot]

[[# heat-map-note]]
++ [#heat-map heat map]

[[# shaded-surface-plot-note]]
++ [#shaded-surface-plot shaded surface plot]

[[# light-source-note]]
++ [#light-source light source]

[[# mesh-surface-plot-note]]
++ [#mesh-surface-plot mesh surface plot]

[[# view-point-note]]
++ [#view-point view point]

[[# vector-field-plot-note]]
++ [#vector-field-plot vector field plot]

[[# chart-options-note]]
+ [#chart-options Chart Options]

[[# chart-title-note]]
++ [#chart-title chart title]

[[# axis-label-note]]
++ [#axis-label axis label]

[[# legend-note]]
++ [#legend legend]

[[# data-label-note]]
++ [#data-label data label]

[[# named-colors-note]]
++ [#named-colors named colors]

[[# rgb-color-note]]
++ [#rgb-color rgb color]

[[# background-color-note]]
++ [#background-color background color]

[[# axis-limits-note]]
++ [#axis-limits axis limits]

[[# logarithmic-y-axis-note]]
++ [#logarithmic-y-axis logarithmic y-axis]

[[# aspect-ratio-note]]
++ [#aspect-ratio aspect ratio]

[[# ticks-note]]
++ [#ticks ticks]

[[# grid-lines-note]]
++ [#grid-lines grid lines]

[[# grid-of-subplots-note]]
++ [#grid-of-subplots grid of subplots]

[[# save-plot-as-png-note]]
++ [#save-plot-as-png save plot as png]

[[# mathematica]]
+ [#top Mathematica]

[http://reference.wolfram.com/mathematica/guide/Mathematica.html Mathematica Documentation Center]
[http://wolframalpha.com WolframAlpha]

[[# sympy]]
+ [#top SymPy]

[http://docs.sympy.org/latest/index.html Welcome to SymPys documentation!]

[[# sage]]
+ [#top Sage]

http://doc.sagemath.org/html/en/index.html

[[# maxima]]
+ [#top Maxima]

http://maxima.sourceforge.net/docs/manual/maxima.html